{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Econometric Game__: Effect of electoral accountability on corruption?\n",
    "   \n",
    "### Team 3: Katheryn Ding, Amber Wei, Max Ye\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from scipy.special import expit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['uf', 'nsorteio', 'totrecursos', 'tot_os', 'pop', 'purb',\n",
       "       'p_secundario', 'cod_ibge6', 'pib_capita_02', 'op_01_04',\n",
       "       ...\n",
       "       'uf_d18', 'uf_d19', 'uf_d20', 'uf_d21', 'uf_d22', 'uf_d23', 'uf_d24',\n",
       "       'uf_d25', 'uf_d26', 'esample2'],\n",
       "      dtype='object', length=116)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corruption_df = pd.read_stata(\"corruptiondata.dta\")\n",
    "corruption_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mayor Covariates: ['pref_idade_tse', 'pref_masc', 'pref_escola', 'winmargin2000', 'exp_prefeito', 'party_d1', 'party_d3', 'party_d4', 'party_d5', 'party_d6', 'party_d7', 'party_d8', 'party_d9', 'party_d10', 'party_d11', 'party_d12', 'party_d13', 'party_d14', 'party_d15', 'party_d16', 'party_d17', 'party_d18']\n",
      "Municipal Covariates: ['lpop', 'purb', 'p_secundario', 'mun_novo', 'lpib02', 'gini_ipea']\n",
      "Political and Judicial Covariates: ['ENEP2000', 'ENLP2000', 'p_cad_pref']\n",
      "Dummy Covariates: ['sorteio1', 'sorteio2', 'sorteio3', 'sorteio4', 'sorteio5', 'sorteio6', 'sorteio7', 'sorteio8', 'sorteio9', 'sorteio10', 'uf_d1', 'uf_d2', 'uf_d3', 'uf_d4', 'uf_d5', 'uf_d6', 'uf_d7', 'uf_d8', 'uf_d9', 'uf_d10', 'uf_d11', 'uf_d12', 'uf_d13', 'uf_d14', 'uf_d15', 'uf_d16', 'uf_d17', 'uf_d18', 'uf_d19', 'uf_d20', 'uf_d21', 'uf_d22', 'uf_d23', 'uf_d24', 'uf_d25', 'uf_d26']\n"
     ]
    }
   ],
   "source": [
    "# Define covariates for each category\n",
    "\n",
    "# Mayor characteristics\n",
    "mayor_covariates = [\n",
    "    \"pref_idade_tse\",  # Age\n",
    "    \"pref_masc\",       # Gender\n",
    "    \"pref_escola\",     # Schooling\n",
    "    \"winmargin2000\",   # Margin of victory in 2000\n",
    "    \"exp_prefeito\"     # Was previously a mayor in a consecutive term\n",
    "] + [col for col in corruption_df.columns if col.startswith(\"party_d\")]\n",
    "\n",
    "# Municipal characteristics\n",
    "municipal_covariates = [\n",
    "    \"lpop\",           # Log of population in 2000\n",
    "    \"purb\",           # Percentage of population in urban sectors\n",
    "    \"p_secundario\",   # Percentage with at least secondary education\n",
    "    \"mun_novo\",       # New municipality indicator\n",
    "    \"lpib02\",         # Log of GDP per capita in 2002\n",
    "    \"gini_ipea\"       # Gini coefficient\n",
    "]\n",
    "\n",
    "# Political and Judicial characteristics\n",
    "political_judicial_covariates = [\n",
    "    \"ENEP2000\",  # Effective number of parties in 2000 mayor elections\n",
    "    \"ENLP2000\",  # Effective number of parties in 2000 legislative elections\n",
    "    \"p_cad_pref\" # Proportion of legislators from the same party as the mayor\n",
    "]\n",
    "\n",
    "# Dummies\n",
    "dummy_covariates = [\n",
    "    col for col in corruption_df.columns if col.startswith(\"uf_d\") or col.startswith(\"sorteio\")\n",
    "]\n",
    "\n",
    "\n",
    "print(\"Mayor Covariates:\", mayor_covariates)\n",
    "print(\"Municipal Covariates:\", municipal_covariates)\n",
    "print(\"Political and Judicial Covariates:\", political_judicial_covariates)\n",
    "print(\"Dummy Covariates:\", dummy_covariates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Columns: Index(['first', 'pcorrupt', 'ncorrupt_os', 'log_valor_corrupt',\n",
      "       'pref_idade_tse', 'pref_masc', 'pref_escola', 'winmargin2000',\n",
      "       'exp_prefeito', 'party_d1', 'party_d3', 'party_d4', 'party_d5',\n",
      "       'party_d6', 'party_d7', 'party_d8', 'party_d9', 'party_d10',\n",
      "       'party_d11', 'party_d12', 'party_d13', 'party_d14', 'party_d15',\n",
      "       'party_d16', 'party_d17', 'party_d18', 'lpop', 'purb', 'p_secundario',\n",
      "       'mun_novo', 'lpib02', 'gini_ipea', 'ENEP2000', 'ENLP2000', 'p_cad_pref',\n",
      "       'sorteio1', 'sorteio2', 'sorteio3', 'sorteio4', 'sorteio5', 'sorteio6',\n",
      "       'sorteio7', 'sorteio8', 'sorteio9', 'sorteio10', 'uf_d1', 'uf_d2',\n",
      "       'uf_d3', 'uf_d4', 'uf_d5', 'uf_d6', 'uf_d7', 'uf_d8', 'uf_d9', 'uf_d10',\n",
      "       'uf_d11', 'uf_d12', 'uf_d13', 'uf_d14', 'uf_d15', 'uf_d16', 'uf_d17',\n",
      "       'uf_d18', 'uf_d19', 'uf_d20', 'uf_d21', 'uf_d22', 'uf_d23', 'uf_d24',\n",
      "       'uf_d25', 'uf_d26'],\n",
      "      dtype='object')\n",
      "Number of rows in the Dataset: 467\n"
     ]
    }
   ],
   "source": [
    "corruption_df[\"log_valor_corrupt\"] = np.log(corruption_df[\"valor_corrupt\"] + 1)\n",
    "\n",
    "# Define the treatment and outcome variables\n",
    "treatment = \"first\"  \n",
    "outcomes = [\"pcorrupt\", \"ncorrupt_os\", 'log_valor_corrupt'] \n",
    "\n",
    "# Use all covariates\n",
    "all_covariates = (\n",
    "    mayor_covariates +\n",
    "    municipal_covariates +\n",
    "    political_judicial_covariates +\n",
    "    dummy_covariates\n",
    ")\n",
    "#set up dataset:\n",
    "required_columns = [treatment] + outcomes + all_covariates\n",
    "double_ml_dataset = corruption_df[required_columns].dropna()\n",
    "\n",
    "print(\"Dataset Columns:\", double_ml_dataset.columns)\n",
    "print(\"Number of rows in the Dataset:\", double_ml_dataset.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assuming Heterogeneosity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to estimate propensity scores using Lasso\n",
    "def estimate_propensity_scores_lasso(X_train, D_train, X_test):\n",
    "    lasso_pscore = LassoCV(alphas=np.logspace(-4, 0, 50), cv=5, random_state=42).fit(X_train, D_train)\n",
    "    D_pred = lasso_pscore.predict(X_test)\n",
    "    propensity_scores = expit(D_pred)  # Convert to probabilities\n",
    "    return propensity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to estimate outcome model using Lasso for treated and untreated groups\n",
    "def estimate_outcome_lasso(X_train, Y_train, D_train, X_test, treated):\n",
    "    if treated:\n",
    "        X_train_filtered = X_train[D_train == 1]\n",
    "        Y_train_filtered = Y_train[D_train == 1]\n",
    "    else:\n",
    "        X_train_filtered = X_train[D_train == 0]\n",
    "        Y_train_filtered = Y_train[D_train == 0]\n",
    "\n",
    "    # Fit Lasso model\n",
    "    lasso_model = LassoCV(alphas=np.logspace(-4, 0, 50), cv=5, random_state=42)\n",
    "    lasso_model.fit(X_train_filtered, Y_train_filtered)\n",
    "    \n",
    "    # Predict on test set\n",
    "    return lasso_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform doubly robust estimation with cross-fitting\n",
    "def doubly_robust_estimation_lasso(X, D, Y, k_folds=5):\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    W_hat_dr_values = []\n",
    "    mse_fold = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_scaled):\n",
    "        X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "        D_train, D_test = D.iloc[train_index], D.iloc[test_index]\n",
    "        Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "        \n",
    "        # Step 1: Estimate propensity scores\n",
    "        propensity_scores = estimate_propensity_scores_lasso(X_train, D_train, X_test)\n",
    "        \n",
    "        # Trim propensity scores\n",
    "        trimmed_indices = (propensity_scores > 0.01) & (propensity_scores < 0.99)\n",
    "        trimmed_X = X_test[trimmed_indices]\n",
    "        trimmed_D = D_test.iloc[trimmed_indices]\n",
    "        trimmed_Y = Y_test.iloc[trimmed_indices]\n",
    "        trimmed_pscore = propensity_scores[trimmed_indices]\n",
    "        \n",
    "        # Step 2: Estimate outcome models for treated and untreated groups\n",
    "        gamma1 = estimate_outcome_lasso(X_train, Y_train, D_train, trimmed_X, treated=True)\n",
    "        gamma0 = estimate_outcome_lasso(X_train, Y_train, D_train, trimmed_X, treated=False)\n",
    "        \n",
    "        # Step 3: Doubly Robust Estimates\n",
    "        trimmed_data = pd.DataFrame({\n",
    "            \"gamma1\": gamma1,\n",
    "            \"gamma0\": gamma0,\n",
    "            \"D\": trimmed_D.values,\n",
    "            \"Y\": trimmed_Y.values,\n",
    "            \"pscore\": trimmed_pscore,\n",
    "        })\n",
    "        \n",
    "        trimmed_data['Y1_dr'] = trimmed_data['gamma1'] + \\\n",
    "            (trimmed_data['D'] / trimmed_data['pscore']) * (trimmed_data['Y'] - trimmed_data['gamma1'])\n",
    "        \n",
    "        trimmed_data['Y0_dr'] = trimmed_data['gamma0'] + \\\n",
    "            ((1 - trimmed_data['D']) / (1 - trimmed_data['pscore'])) * (trimmed_data['Y'] - trimmed_data['gamma0'])\n",
    "        \n",
    "        # Step 4: Calculate treatment effect and MSE\n",
    "        W_hat_dr_values.append(np.mean(trimmed_data['Y1_dr'] - trimmed_data['Y0_dr']))\n",
    "        mse_fold.append(mean_squared_error(\n",
    "            trimmed_data['Y'], \n",
    "            trimmed_data['Y1_dr'] * trimmed_data['D'] + trimmed_data['Y0_dr'] * (1 - trimmed_data['D'])\n",
    "        ))\n",
    "    \n",
    "    # Return average treatment effect and MSE\n",
    "    return np.mean(W_hat_dr_values), np.mean(mse_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to loop through outcomes and store results\n",
    "def estimate_dr_for_outcomes_lasso(double_ml_dataset, covariates, treatment, outcomes):\n",
    "    theta_hat_dr_values = []\n",
    "    mse_values = []\n",
    "\n",
    "    for outcome in outcomes:\n",
    "        X = double_ml_dataset[covariates]\n",
    "        D = double_ml_dataset[treatment]\n",
    "        Y = double_ml_dataset[outcome]\n",
    "        \n",
    "        dr_ate, mse = doubly_robust_estimation_lasso(X, D, Y)\n",
    "        theta_hat_dr_values.append(dr_ate)\n",
    "        mse_values.append(mse)\n",
    "    \n",
    "    # Create Results DataFrame\n",
    "    result_df = pd.DataFrame({\n",
    "        \"Outcome\": outcomes,\n",
    "        \"Estimate\": theta_hat_dr_values,\n",
    "        \"MSE\": mse_values\n",
    "    })\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doubly Robust Treatment Effect Estimates with Cross-Fitting using Lasso:\n",
      "             Outcome  Estimate        MSE\n",
      "0           pcorrupt -0.022035   0.017367\n",
      "1        ncorrupt_os -0.008515   0.003262\n",
      "2  log_valor_corrupt -1.067475  36.140774\n"
     ]
    }
   ],
   "source": [
    "result_df = estimate_dr_for_outcomes_lasso(double_ml_dataset, all_covariates, treatment, outcomes)\n",
    "print(\"Doubly Robust Treatment Effect Estimates with Cross-Fitting using Lasso:\")\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized Mean Differences (SMD):\n",
      "[ 0.104372   -0.04765426  0.02968724 -0.38068098  0.38181138  0.19310077\n",
      " -0.0484961  -0.12084576  0.10655728  0.06272838  0.08174942  0.08930089\n",
      "  0.0956954   0.16994452 -0.07496204 -0.141793    0.11795554  0.14579037\n",
      "  0.13770705  0.08130773  0.09544342 -0.09380843  0.06517223  0.17611495\n",
      "  0.2541373  -0.08120754  0.10690512  0.127647    0.30606577  0.32192838\n",
      " -0.4765111   0.00553448 -0.09751498 -0.03301595  0.02807158  0.00833995\n",
      " -0.03725498 -0.00081405  0.04965926 -0.07079715  0.14603858  0.07495855\n",
      " -0.10515903 -0.12186608  0.22405127  0.08188919  0.04810288  0.00320493\n",
      "  0.03633524 -0.08662325  0.05773501  0.01315004  0.00978864  0.05808311\n",
      " -0.11713681 -0.11842766 -0.04898335 -0.07461609 -0.1673562  -0.06620508\n",
      " -0.13794576  0.03507964  0.1753901   0.05958109 -0.09663015  0.12857486\n",
      "  0.04806826]\n"
     ]
    }
   ],
   "source": [
    "def compute_propensity_scores(X, D):\n",
    "    lasso_pscore = LassoCV(alphas=np.logspace(-4, 0, 50), cv=5, random_state=42)\n",
    "    lasso_pscore.fit(X, D)\n",
    "    propensity_scores = expit(lasso_pscore.predict(X))  # Convert to probabilities using expit\n",
    "    return propensity_scores\n",
    "def compute_smd(double_ml_dataset, covariates, treatment):\n",
    "    X = double_ml_dataset[covariates].values\n",
    "    D = double_ml_dataset[treatment].values\n",
    "    # Estimate propensity scores\n",
    "    pscore = compute_propensity_scores(X, D)\n",
    "    \n",
    "    # Create weights\n",
    "    weights_treated = 1 / pscore\n",
    "    weights_control = 1 / (1 - pscore)\n",
    "    \n",
    "    # Treated and control indices\n",
    "    treated_indices = (D == 1)\n",
    "    control_indices = (D == 0)\n",
    "    \n",
    "    # Compute weighted means\n",
    "    weighted_means_treated = np.average(X[treated_indices], axis=0, weights=weights_treated[treated_indices])\n",
    "    weighted_means_control = np.average(X[control_indices], axis=0, weights=weights_control[control_indices])\n",
    "    \n",
    "    # Compute pooled standard deviation\n",
    "    pooled_std = np.sqrt((np.var(X[treated_indices], axis=0) + np.var(X[control_indices], axis=0)) / 2)\n",
    "    \n",
    "    # Compute Standardized Mean Differences (SMD)\n",
    "    smd = (weighted_means_treated - weighted_means_control) / pooled_std\n",
    "    \n",
    "    return smd\n",
    "\n",
    "# Example usage\n",
    "smd_values = compute_smd(double_ml_dataset, all_covariates, treatment)\n",
    "\n",
    "\n",
    "# Print only the SMD\n",
    "print(\"Standardized Mean Differences (SMD):\")\n",
    "print(smd_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not very balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assuming Homogeneous treatment effct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_outcome_lasso(X_train, Y_train, X_test):\n",
    "    outcome_model = LassoCV(alphas=np.logspace(-4, 0, 50), cv=5, random_state=42)\n",
    "    outcome_model.fit(X_train, Y_train)\n",
    "    gamma_hat = outcome_model.predict(X_test)\n",
    "    return gamma_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to estimate E[D|X] using Lasso\n",
    "def estimate_propensity_lasso(X_train, D_train, X_test):\n",
    "    pscore_model = LassoCV(alphas=np.logspace(-4, 0, 50), cv=5, random_state=42)\n",
    "    pscore_model.fit(X_train, D_train)\n",
    "    pi_hat = pscore_model.predict(X_test)\n",
    "    return pi_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform doubly robust estimation with cross-fitting\n",
    "def doubly_robust_crossfit_lasso(X, D, Y, k_folds=5):\n",
    "    # Standardize features within this function\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Initialize variables\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    W_hat, V_hat = np.zeros(len(Y)), np.zeros(len(Y))\n",
    "    mse_fold = []  # List to store MSE for each fold\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_scaled):\n",
    "        X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "        D_train, D_test = D[train_index], D[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "        \n",
    "        # Step 1: Estimate outcome E[Y|X]\n",
    "        gamma_hat = estimate_outcome_lasso(X_train, Y_train, X_test)\n",
    "        \n",
    "        # Step 2: Estimate propensity scores E[D|X]\n",
    "        pi_hat = estimate_propensity_lasso(X_train, D_train, X_test)\n",
    "        \n",
    "        # Step 3: Calculate residuals\n",
    "        W_hat[test_index] = Y_test - gamma_hat\n",
    "        V_hat[test_index] = D_test - pi_hat\n",
    "        \n",
    "        # Step 4: Calculate MSE for this fold\n",
    "        mse_fold.append(mean_squared_error(Y_test, gamma_hat))\n",
    "    \n",
    "    # Step 5: Regress residuals W_hat on V_hat to estimate theta_0\n",
    "    regression = LinearRegression()\n",
    "    regression.fit(V_hat.reshape(-1, 1), W_hat)\n",
    "    theta_hat = regression.coef_[0]\n",
    "    \n",
    "    return theta_hat, np.mean(mse_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_dr_homogeneous_lasso(double_ml_dataset, all_covariates, treatment, outcomes):\n",
    "    theta_hat_dr_values = []\n",
    "    mse_values = []\n",
    "\n",
    "    for outcome in outcomes:\n",
    "        X = double_ml_dataset[all_covariates].values\n",
    "        D = double_ml_dataset[treatment].values\n",
    "        Y = double_ml_dataset[outcome].values\n",
    "        \n",
    "        theta_hat, mse = doubly_robust_crossfit_lasso(X, D, Y)\n",
    "        theta_hat_dr_values.append(theta_hat)\n",
    "        mse_values.append(mse)\n",
    "    \n",
    "    # Create Results DataFrame\n",
    "    result_df = pd.DataFrame({\n",
    "        \"Outcome\": outcomes,\n",
    "        \"Estimate\": theta_hat_dr_values,\n",
    "        \"MSE\": mse_values\n",
    "    })\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doubly Robust Treatment Effect Estimates with Cross-Fitting (Homogeneous):\n",
      "             Outcome  Estimate        MSE\n",
      "0           pcorrupt -0.023304   0.010267\n",
      "1        ncorrupt_os -0.008581   0.002078\n",
      "2  log_valor_corrupt -1.205078  24.754757\n"
     ]
    }
   ],
   "source": [
    "ls_result_df_homo = estimate_dr_homogeneous_lasso(double_ml_dataset, all_covariates, treatment, outcomes)\n",
    "\n",
    "# Print the results\n",
    "print(\"Doubly Robust Treatment Effect Estimates with Cross-Fitting (Homogeneous):\")\n",
    "print(ls_result_df_homo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assuming Heterogeneous Treatment Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_propensity_scores_rf(X_train, D_train, X_test, n_estimators=100, max_depth=5, random_state=42):\n",
    "    rf_pscore = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=random_state)\n",
    "    rf_pscore.fit(X_train, D_train)\n",
    "    propensity_scores = rf_pscore.predict_proba(X_test)[:, 1]  # Probability of treatment\n",
    "    return propensity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to estimate outcome models for treated and untreated groups using Random Forest\n",
    "def estimate_outcome_rf(X_train, Y_train, X_test, D_train, treated=True, n_estimators=100, max_depth=5, random_state=42):\n",
    "    rf_model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=random_state)\n",
    "    if treated:\n",
    "        rf_model.fit(X_train[D_train == 1], Y_train[D_train == 1])\n",
    "    else:\n",
    "        rf_model.fit(X_train[D_train == 0], Y_train[D_train == 0])\n",
    "    return rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate doubly robust estimates for a single outcome\n",
    "def calculate_dr_estimates_rf(X, D, Y, k_folds=5):\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    dr_ate_fold = []\n",
    "    mse_fold = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X_scaled):\n",
    "        X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "        D_train, D_test = D.iloc[train_index], D.iloc[test_index]\n",
    "        Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "        \n",
    "        # Step 1: Estimate propensity scores\n",
    "        propensity_scores = estimate_propensity_scores_rf(X_train, D_train, X_test)\n",
    "\n",
    "        # Step 2: Trim propensity scores\n",
    "        trimmed_indices = (propensity_scores > 0.01) & (propensity_scores < 0.99)\n",
    "        trimmed_X = X_test[trimmed_indices]\n",
    "        trimmed_D = D_test.iloc[trimmed_indices]\n",
    "        trimmed_Y = Y_test.iloc[trimmed_indices]\n",
    "        trimmed_pscore = propensity_scores[trimmed_indices]\n",
    "\n",
    "        # Step 3: Estimate outcome models for treated and untreated\n",
    "        gamma1 = estimate_outcome_rf(X_train, Y_train, trimmed_X, D_train, treated=True)\n",
    "        gamma0 = estimate_outcome_rf(X_train, Y_train, trimmed_X, D_train, treated=False)\n",
    "\n",
    "        # Step 4: Construct doubly robust estimates\n",
    "        trimmed_data = pd.DataFrame({\n",
    "            \"gamma1\": gamma1,\n",
    "            \"gamma0\": gamma0,\n",
    "            \"D\": trimmed_D.values,\n",
    "            \"Y\": trimmed_Y.values,\n",
    "            \"pscore\": trimmed_pscore\n",
    "        })\n",
    "\n",
    "        trimmed_data['Y1_dr'] = (\n",
    "            trimmed_data['gamma1'] +\n",
    "            (trimmed_data['D'] / trimmed_data['pscore']) * (trimmed_data['Y'] - trimmed_data['gamma1'])\n",
    "        )\n",
    "        trimmed_data['Y0_dr'] = (\n",
    "            trimmed_data['gamma0'] +\n",
    "            ((1 - trimmed_data['D']) / (1 - trimmed_data['pscore'])) * (trimmed_data['Y'] - trimmed_data['gamma0'])\n",
    "        )\n",
    "\n",
    "        # Step 5: Calculate treatment effect and MSE\n",
    "        dr_ate_fold.append(np.mean(trimmed_data['Y1_dr'] - trimmed_data['Y0_dr']))\n",
    "        mse_fold.append(mean_squared_error(\n",
    "            trimmed_data['Y'], \n",
    "            trimmed_data['Y1_dr'] * trimmed_data['D'] + trimmed_data['Y0_dr'] * (1 - trimmed_data['D'])\n",
    "        ))\n",
    "    \n",
    "    # Average results across folds\n",
    "    dr_ate = np.mean(dr_ate_fold)\n",
    "    mse = np.mean(mse_fold)\n",
    "    return dr_ate, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to loop through all outcomes and calculate results\n",
    "def run_dr_estimation_rf(dataset, covariates, treatment, outcomes):\n",
    "    theta_hat_dr_values = []\n",
    "    mse_values = []\n",
    "\n",
    "    for outcome in outcomes:\n",
    "        print(f\"Processing outcome: {outcome}\")\n",
    "        X = dataset[covariates]\n",
    "        D = dataset[treatment]\n",
    "        Y = dataset[outcome]\n",
    "        \n",
    "        dr_ate, mse = calculate_dr_estimates_rf(X, D, Y)\n",
    "        theta_hat_dr_values.append(dr_ate)\n",
    "        mse_values.append(mse)\n",
    "    \n",
    "    # Create Results DataFrame\n",
    "    results_df = pd.DataFrame({\n",
    "        \"Outcome\": outcomes,\n",
    "        \"Estimate\": theta_hat_dr_values,\n",
    "        \"MSE\": mse_values\n",
    "    })\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing outcome: pcorrupt\n",
      "Processing outcome: ncorrupt_os\n",
      "Processing outcome: log_valor_corrupt\n",
      "Doubly Robust Treatment Effect Estimates with Cross-Fitting (Random Forest):\n",
      "             Outcome  Estimate        MSE\n",
      "0           pcorrupt -0.026246   0.018019\n",
      "1        ncorrupt_os -0.007434   0.002945\n",
      "2  log_valor_corrupt -0.910680  33.156128\n"
     ]
    }
   ],
   "source": [
    "rf_result_df_hetero = run_dr_estimation_rf(\n",
    "    dataset=double_ml_dataset, \n",
    "    covariates=all_covariates, \n",
    "    treatment=treatment, \n",
    "    outcomes=outcomes\n",
    ")\n",
    "\n",
    "# Print the final results\n",
    "print(\"Doubly Robust Treatment Effect Estimates with Cross-Fitting (Random Forest):\")\n",
    "print(rf_result_df_hetero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized Mean Differences (SMD):\n",
      "[ 0.06558709 -0.04899405 -0.00106626 -0.29304137  0.36982794  0.20952734\n",
      " -0.0443829  -0.10723244  0.08466159  0.07859063  0.07887369  0.08302273\n",
      "  0.06478372  0.17108093 -0.06431373 -0.15535929  0.12530652  0.14007413\n",
      "  0.13658106  0.08332839  0.08777559 -0.09634819 -0.0112643   0.05041207\n",
      "  0.12867463 -0.0300527   0.04889403  0.12869706  0.19468053  0.20856626\n",
      " -0.35231704  0.00814893 -0.08209678 -0.0428761   0.022087    0.02805476\n",
      " -0.03007489  0.00071295  0.02754137 -0.06592755  0.1337333   0.09644191\n",
      " -0.0837574  -0.11902339  0.20411795  0.09864509  0.07200407 -0.03468904\n",
      "  0.03025831 -0.06524535  0.02816652  0.00475782  0.00601626  0.06005698\n",
      " -0.08238073 -0.10178711 -0.01367828 -0.10251496 -0.19683067 -0.03652178\n",
      " -0.13499757  0.00736641  0.16936891  0.04743023 -0.08062995  0.10341781\n",
      "  0.04708293]\n"
     ]
    }
   ],
   "source": [
    "def compute_propensity_scores(X, D):\n",
    "    rf_pscore = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "    rf_pscore.fit(X, D)\n",
    "    propensity_scores = rf_pscore.predict_proba(X)[:, 1]  # Probability of treatment (D=1)\n",
    "    return propensity_scores\n",
    "\n",
    "smd_values = compute_smd(double_ml_dataset, all_covariates, treatment)\n",
    "\n",
    "\n",
    "# Print only the SMD\n",
    "print(\"Standardized Mean Differences (SMD):\")\n",
    "print(smd_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assuming Homogeneous Treatment Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to estimate E[Y|X] using Random Forest for the outcome model\n",
    "def estimate_outcome_rf_homo(X_train, Y_train, X_test, n_estimators=100, max_depth=5, random_state=42):\n",
    "    rf_model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=random_state)\n",
    "    rf_model.fit(X_train, Y_train)\n",
    "    return rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate residuals (W_hat and V_hat)\n",
    "def calculate_residuals_rf_homo(X_train, X_test, Y_train, Y_test, D_train, D_test):\n",
    "    # Estimate E[Y|X] using Random Forest (Outcome model)\n",
    "    gamma_hat = estimate_outcome_rf_homo(X_train, Y_train, X_test)\n",
    "\n",
    "    # Estimate E[D|X] using Random Forest (Propensity score model)\n",
    "    pi_hat = estimate_propensity_scores_rf(X_train, D_train, X_test)\n",
    "    \n",
    "    W_hat = Y_test - gamma_hat\n",
    "    V_hat = D_test - pi_hat\n",
    "    \n",
    "    return W_hat, V_hat, gamma_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate doubly robust estimates for homogeneous effects\n",
    "def calculate_dr_estimates_rf_homo(X, D, Y, k_folds=5):\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    W_hat, V_hat = np.zeros(len(Y)), np.zeros(len(Y))\n",
    "    mse_fold = []  # List to store MSE for each fold\n",
    "\n",
    "    for train_index, test_index in kf.split(X_scaled):\n",
    "        X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "        D_train, D_test = D[train_index], D[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "        \n",
    "        # Calculate residuals\n",
    "        W_hat[test_index], V_hat[test_index], gamma_hat = calculate_residuals(\n",
    "            X_train, X_test, Y_train, Y_test, D_train, D_test\n",
    "        )\n",
    "        \n",
    "        # Calculate MSE for this fold\n",
    "        mse_fold.append(mean_squared_error(Y_test, gamma_hat))\n",
    "\n",
    "    # Regress W_hat on V_hat to estimate theta_0\n",
    "    regression = LinearRegression()\n",
    "    regression.fit(V_hat.reshape(-1, 1), W_hat)\n",
    "    theta_hat = regression.coef_[0]\n",
    "\n",
    "    return theta_hat, np.mean(mse_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run DR estimation for multiple outcomes\n",
    "def run_dr_estimation_rf_homo(dataset, covariates, treatment, outcomes):\n",
    "    theta_hat_dr_values = []\n",
    "    mse_values = []\n",
    "\n",
    "    for outcome in outcomes:\n",
    "        print(f\"Processing outcome: {outcome}\")\n",
    "        X = dataset[covariates].values\n",
    "        D = dataset[treatment].values\n",
    "        Y = dataset[outcome].values\n",
    "        \n",
    "        theta_hat, mse = calculate_dr_estimates_rf_homo(X, D, Y)\n",
    "        theta_hat_dr_values.append(theta_hat)\n",
    "        mse_values.append(mse)\n",
    "    \n",
    "    # Create Results DataFrame\n",
    "    results_df = pd.DataFrame({\n",
    "        \"Outcome\": outcomes,\n",
    "        \"Estimate\": theta_hat_dr_values,\n",
    "        \"MSE\": mse_values\n",
    "    })\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing outcome: pcorrupt\n",
      "Processing outcome: ncorrupt_os\n",
      "Processing outcome: log_valor_corrupt\n",
      "Doubly Robust Treatment Effect Estimates with Cross-Fitting (Homogeneous) using Random Forest:\n",
      "             Outcome  Estimate        MSE\n",
      "0           pcorrupt -0.021572   0.011728\n",
      "1        ncorrupt_os -0.006105   0.002650\n",
      "2  log_valor_corrupt -0.876484  26.331269\n"
     ]
    }
   ],
   "source": [
    "rf_result_df_homo = run_dr_estimation_rf_homo(\n",
    "    dataset=double_ml_dataset, \n",
    "    covariates=all_covariates, \n",
    "    treatment=treatment, \n",
    "    outcomes=outcomes\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "print(\"Doubly Robust Treatment Effect Estimates with Cross-Fitting (Homogeneous) using Random Forest:\")\n",
    "print(rf_result_df_homo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doubly Robust Treatment Effect Estimates with Cross-Fitting (Homogeneous) using Random Forest:\n",
      "             Outcome  Estimate        MSE\n",
      "0           pcorrupt -0.024575   0.010883\n",
      "1        ncorrupt_os -0.007833   0.002269\n",
      "2  log_valor_corrupt -0.966588  26.056496\n"
     ]
    }
   ],
   "source": [
    "theta_hat_dr_values = []\n",
    "mse_values = []\n",
    "\n",
    "# Loop through each outcome\n",
    "for outcome in outcomes:\n",
    "    \n",
    "    X = double_ml_dataset[all_covariates].values\n",
    "    D = double_ml_dataset[treatment].values\n",
    "    Y = double_ml_dataset[outcome].values\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # K-Fold Cross-Fitting\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    W_hat, V_hat = np.zeros(len(Y)), np.zeros(len(Y))\n",
    "    mse_fold = []  # List to store MSE for each fold\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_scaled):\n",
    "        X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "        D_train, D_test = D[train_index], D[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "        # Step 1: Estimate E[Y|X] using Random Forest (Outcome model)\n",
    "        outcome_model = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
    "        outcome_model.fit(X_train, Y_train)\n",
    "        gamma_hat = outcome_model.predict(X_test)\n",
    "\n",
    "        # Step 2: Estimate E[D|X] using Random Forest (Propensity score model)\n",
    "        pscore_model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "        pscore_model.fit(X_train, D_train)\n",
    "        pi_hat = pscore_model.predict_proba(X_test)[:, 1]  # Probability of treatment\n",
    "        \n",
    "        # Step 3: Calculate residuals W_hat and V_hat\n",
    "        W_hat[test_index] = Y_test - gamma_hat\n",
    "        V_hat[test_index] = D_test - pi_hat\n",
    "\n",
    "        # Step 4: Calculate MSE for this fold\n",
    "        mse_fold.append(mean_squared_error(Y_test, gamma_hat))\n",
    "\n",
    "    # Step 5: Regress W_hat on V_hat to estimate theta_0\n",
    "    regression = LinearRegression()\n",
    "    regression.fit(V_hat.reshape(-1, 1), W_hat)\n",
    "    theta_hat = regression.coef_[0]\n",
    "    \n",
    "    # Store results\n",
    "    theta_hat_dr_values.append(theta_hat)\n",
    "    mse_values.append(np.mean(mse_fold))  # Average MSE across folds\n",
    "\n",
    "# Step 6: Create Results DataFrame\n",
    "rf_result_df_homo = pd.DataFrame({\n",
    "    \"Outcome\": outcomes,\n",
    "    \"Estimate\": theta_hat_dr_values,\n",
    "    \"MSE\": mse_values\n",
    "})\n",
    "\n",
    "# Display the results DataFrame\n",
    "print(\"Doubly Robust Treatment Effect Estimates with Cross-Fitting (Homogeneous) using Random Forest:\")\n",
    "print(rf_result_df_homo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build and train an MLP model\n",
    "def train_mlp(X_train, Y_train, input_dim, output_activation='linear', loss='mse', verbose=0):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(input_dim,)),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation=output_activation)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['mae'])\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    model.fit(X_train, Y_train, validation_split=0.2, epochs=100, batch_size=32,\n",
    "              callbacks=[early_stopping], verbose=verbose)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate doubly robust treatment effects using MLP\n",
    "def double_ml_mlp_heterogeneous(X, D, Y, outcomes):\n",
    "    theta_hat_dr_values = []\n",
    "    mse_values = []\n",
    "\n",
    "    # Standardize covariates\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # 5-Fold Cross-Fitting\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    for outcome in outcomes:\n",
    "        dr_ate_fold = []\n",
    "        mse_fold = []\n",
    "        \n",
    "        for train_index, test_index in kf.split(X_scaled):\n",
    "            X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "            D_train, D_test = D[train_index], D[test_index]\n",
    "            Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "            \n",
    "            # Step 1: Propensity score estimation using MLP\n",
    "            model_pscore = train_mlp(X_train, D_train, input_dim=X_train.shape[1], \n",
    "                                     output_activation='sigmoid', loss='binary_crossentropy')\n",
    "            propensity_scores = model_pscore.predict(X_test).flatten()\n",
    "\n",
    "            # Trim p-scores (0.01, 0.99)\n",
    "            trimmed_indices = (propensity_scores > 0.01) & (propensity_scores < 0.99)\n",
    "            trimmed_X = X_test[trimmed_indices]\n",
    "            trimmed_D = D_test[trimmed_indices]\n",
    "            trimmed_Y = Y_test[trimmed_indices]\n",
    "            trimmed_pscore = propensity_scores[trimmed_indices]\n",
    "\n",
    "            # Step 2: Fit outcome models for treated and untreated groups\n",
    "            model_treated = train_mlp(X_train[D_train == 1], Y_train[D_train == 1], input_dim=X_train.shape[1])\n",
    "            gamma1 = model_treated.predict(trimmed_X).flatten()\n",
    "\n",
    "            model_untreated = train_mlp(X_train[D_train == 0], Y_train[D_train == 0], input_dim=X_train.shape[1])\n",
    "            gamma0 = model_untreated.predict(trimmed_X).flatten()\n",
    "\n",
    "            # Step 3: Construct doubly robust estimates\n",
    "            trimmed_data = pd.DataFrame({\n",
    "                \"gamma1\": gamma1,\n",
    "                \"gamma0\": gamma0,\n",
    "                \"D\": trimmed_D,\n",
    "                \"Y\": trimmed_Y,\n",
    "                \"pscore\": trimmed_pscore\n",
    "            })\n",
    "            trimmed_data['Y1_dr'] = (\n",
    "                trimmed_data['gamma1'] +\n",
    "                (trimmed_data['D'] / trimmed_data['pscore']) * (trimmed_data['Y'] - trimmed_data['gamma1'])\n",
    "            )\n",
    "            trimmed_data['Y0_dr'] = (\n",
    "                trimmed_data['gamma0'] +\n",
    "                ((1 - trimmed_data['D']) / (1 - trimmed_data['pscore'])) * (trimmed_data['Y'] - trimmed_data['gamma0'])\n",
    "            )\n",
    "\n",
    "            # Calculate treatment effect and MSE for the fold\n",
    "            dr_ate_fold.append(np.mean(trimmed_data['Y1_dr'] - trimmed_data['Y0_dr']))\n",
    "            mse_fold.append(mean_squared_error(\n",
    "                trimmed_data['Y'], \n",
    "                trimmed_data['Y1_dr'] * trimmed_data['D'] + trimmed_data['Y0_dr'] * (1 - trimmed_data['D'])\n",
    "            ))\n",
    "\n",
    "        # Store average estimates and MSE\n",
    "        theta_hat_dr_values.append(np.mean(dr_ate_fold))\n",
    "        mse_values.append(np.mean(mse_fold))\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        \"Outcome\": outcomes,\n",
    "        \"Estimate\": theta_hat_dr_values,\n",
    "        \"MSE\": mse_values\n",
    "    })\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for easy call \n",
    "def run_double_ml_mlp(dataset, covariants, outcomes):\n",
    "    X = dataset[covariants].values\n",
    "    D = dataset[treatment].values\n",
    "    results = []\n",
    "    \n",
    "    for outcome in outcomes:\n",
    "        Y = dataset[outcome].values\n",
    "        print(f\"Processing outcome: {outcome}\")\n",
    "        result = double_ml_mlp_heterogeneous(X, D, Y, [outcome])\n",
    "        results.append(result)\n",
    "    \n",
    "    final_results = pd.concat(results, ignore_index=True)\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing outcome: pcorrupt\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Processing outcome: ncorrupt_os\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[207], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#mlp_result with all covariants\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m mlp_result_df_hetero \u001b[38;5;241m=\u001b[39m run_double_ml_mlp(double_ml_dataset, all_covariates, outcomes)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoubly Robust Treatment Effect Estimates with Cross-Fitting (Heterogeneous) using MLP:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m mlp_result_df_hetero\n",
      "Cell \u001b[0;32mIn[206], line 10\u001b[0m, in \u001b[0;36mrun_double_ml_mlp\u001b[0;34m(dataset, covariants, outcomes)\u001b[0m\n\u001b[1;32m      8\u001b[0m     Y \u001b[38;5;241m=\u001b[39m dataset[outcome]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing outcome: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutcome\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m     result \u001b[38;5;241m=\u001b[39m double_ml_mlp_heterogeneous(X, D, Y, [outcome])\n\u001b[1;32m     11\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[1;32m     13\u001b[0m final_results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(results, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[205], line 23\u001b[0m, in \u001b[0;36mdouble_ml_mlp_heterogeneous\u001b[0;34m(X, D, Y, outcomes)\u001b[0m\n\u001b[1;32m     20\u001b[0m Y_train, Y_test \u001b[38;5;241m=\u001b[39m Y[train_index], Y[test_index]\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Step 1: Propensity score estimation using MLP\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m model_pscore \u001b[38;5;241m=\u001b[39m train_mlp(X_train, D_train, input_dim\u001b[38;5;241m=\u001b[39mX_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \n\u001b[1;32m     24\u001b[0m                          output_activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     25\u001b[0m propensity_scores \u001b[38;5;241m=\u001b[39m model_pscore\u001b[38;5;241m.\u001b[39mpredict(X_test)\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Trim p-scores (0.01, 0.99)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[204], line 11\u001b[0m, in \u001b[0;36mtrain_mlp\u001b[0;34m(X_train, Y_train, input_dim, output_activation, loss, verbose)\u001b[0m\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39mloss, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     10\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 11\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, Y_train, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m     12\u001b[0m           callbacks\u001b[38;5;241m=\u001b[39m[early_stopping], verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/opt/anaconda3/envs/info2950/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/info2950/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:392\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_epoch_iterator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_epoch_iterator \u001b[38;5;241m=\u001b[39m TFEpochIterator(\n\u001b[1;32m    383\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m    384\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    391\u001b[0m     )\n\u001b[0;32m--> 392\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[1;32m    393\u001b[0m     x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m    394\u001b[0m     y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m    395\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39mval_sample_weight,\n\u001b[1;32m    396\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mvalidation_batch_size \u001b[38;5;129;01mor\u001b[39;00m batch_size,\n\u001b[1;32m    397\u001b[0m     steps\u001b[38;5;241m=\u001b[39mvalidation_steps,\n\u001b[1;32m    398\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m    399\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    400\u001b[0m     _use_cached_eval_dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    401\u001b[0m )\n\u001b[1;32m    402\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    404\u001b[0m }\n\u001b[1;32m    405\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/info2950/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/info2950/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:479\u001b[0m, in \u001b[0;36mTensorFlowTrainer.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_metrics()\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m--> 479\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    480\u001b[0m         callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m    481\u001b[0m         logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_function(iterator)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/info2950/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:729\u001b[0m, in \u001b[0;36mTFEpochIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 729\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epoch_iterator)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/info2950/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:112\u001b[0m, in \u001b[0;36mEpochIterator._enumerate_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_iterator\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_seen \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches:\n\u001b[0;32m--> 112\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_iterator())\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_seen \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/info2950/lib/python3.12/site-packages/tensorflow/python/data/ops/dataset_ops.py:501\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[1;32m    500\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[0;32m--> 501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m iterator_ops\u001b[38;5;241m.\u001b[39mOwnedIterator(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration in eager mode or within tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/info2950/lib/python3.12/site-packages/tensorflow/python/data/ops/iterator_ops.py:709\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    705\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 709\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_iterator(dataset)\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next_call_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/info2950/lib/python3.12/site-packages/tensorflow/python/data/ops/iterator_ops.py:748\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    745\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fulltype\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m    746\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types)\n\u001b[1;32m    747\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mexperimental_set_type(fulltype)\n\u001b[0;32m--> 748\u001b[0m gen_dataset_ops\u001b[38;5;241m.\u001b[39mmake_iterator(ds_variant, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/info2950/lib/python3.12/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3478\u001b[0m, in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   3477\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3478\u001b[0m     _result \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_FastPathExecute(\n\u001b[1;32m   3479\u001b[0m       _ctx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMakeIterator\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, dataset, iterator)\n\u001b[1;32m   3480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3481\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#mlp_result with all covariants\n",
    "mlp_result_df_hetero = run_double_ml_mlp(double_ml_dataset, all_covariates, outcomes)\n",
    "print(\"Doubly Robust Treatment Effect Estimates with Cross-Fitting (Heterogeneous) using MLP:\")\n",
    "mlp_result_df_hetero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Standardized Mean Differences (SMD):\n",
      "[ 0.10255492 -0.09378493 -0.04928849 -0.40372005  0.39896184  0.22005796\n",
      " -0.04089811 -0.13214932  0.11899886  0.09692479  0.06045583  0.0717589\n",
      "  0.02363408  0.14680792 -0.16189747 -0.09694399  0.10458215  0.12504125\n",
      "  0.17975597  0.05891138  0.01978472 -0.17008045 -0.0182573   0.10930817\n",
      "  0.19023459 -0.08055138  0.12916945  0.04918699  0.17569396  0.1997095\n",
      " -0.38437688  0.0193055  -0.07962076 -0.09172229  0.00982546  0.06538795\n",
      " -0.03104956  0.00810566  0.07776392 -0.10873184  0.13596366  0.03891975\n",
      " -0.05494297 -0.16956018  0.19507578  0.08128857  0.0560813  -0.06510179\n",
      "  0.08022884 -0.10965527  0.07538258 -0.07897831  0.00331136  0.1015876\n",
      " -0.08391009 -0.16466638 -0.01569909 -0.07827742 -0.24601324 -0.10535873\n",
      " -0.1218379   0.02186373  0.2896228   0.12830795 -0.05722529  0.09750834\n",
      "  0.01336877]\n"
     ]
    }
   ],
   "source": [
    "def compute_propensity_scores(X, D):\n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Define MLP Model\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(X_scaled.shape[1],)),  # Input layer\n",
    "        Dense(64, activation='relu'),                                    # Hidden layer 1\n",
    "        Dense(32, activation='relu'),                                    # Hidden layer 2\n",
    "        Dense(1, activation='sigmoid')                                   # Output layer for probabilities\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Early stopping to prevent overfitting\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    \n",
    "    # Train the MLP model\n",
    "    model.fit(X_scaled, D, validation_split=0.2, epochs=100, batch_size=32, \n",
    "              callbacks=[early_stopping], verbose=0)\n",
    "    \n",
    "    # Predict propensity scores\n",
    "    propensity_scores = model.predict(X_scaled).flatten()\n",
    "    return propensity_scores\n",
    "\n",
    "smd_values = compute_smd(double_ml_dataset, all_covariates, treatment)\n",
    "\n",
    "\n",
    "# Print only the SMD\n",
    "print(\"Standardized Mean Differences (SMD):\")\n",
    "print(smd_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assuming Homogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp(X_train, Y_train, input_dim, output_activation='linear', loss='mse', verbose=0):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(input_dim,)),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation=output_activation)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['mae'])\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    model.fit(X_train, Y_train, validation_split=0.2, epochs=100, batch_size=32,\n",
    "              callbacks=[early_stopping], verbose=verbose)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform Double ML for a single outcome\n",
    "def double_ml_single_outcome_homogeneous(X, D, Y):\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Prepare for K-Fold Cross-Fitting\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    W_hat, V_hat = np.zeros(len(Y)), np.zeros(len(Y))\n",
    "    mse_fold = []  # List to store MSE for each fold\n",
    "\n",
    "    for train_index, test_index in kf.split(X_scaled):\n",
    "        X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "        D_train, D_test = D[train_index], D[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "        # Step 1: Estimate E[Y|X] using MLP (Outcome model)\n",
    "        outcome_model = train_mlp(X_train, Y_train, input_dim=X_train.shape[1])\n",
    "        gamma_hat = outcome_model.predict(X_test).flatten()\n",
    "\n",
    "        # Step 2: Estimate E[D|X] using MLP (Propensity score model)\n",
    "        pscore_model = train_mlp(X_train, D_train, input_dim=X_train.shape[1], \n",
    "                                 output_activation='sigmoid', loss='binary_crossentropy')\n",
    "        pi_hat = pscore_model.predict(X_test).flatten()\n",
    "\n",
    "        # Step 3: Calculate residuals W_hat and V_hat\n",
    "        W_hat[test_index] = Y_test - gamma_hat\n",
    "        V_hat[test_index] = D_test - pi_hat\n",
    "\n",
    "        # Step 4: Calculate MSE for this fold\n",
    "        mse_fold.append(mean_squared_error(Y_test, gamma_hat))\n",
    "\n",
    "    # Step 5: Regress W_hat on V_hat to estimate theta_0\n",
    "    regression = LinearRegression()\n",
    "    regression.fit(V_hat.reshape(-1, 1), W_hat)\n",
    "    theta_hat = regression.coef_[0]\n",
    "    \n",
    "    return theta_hat, np.mean(mse_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to loop through multiple outcomes\n",
    "def run_double_ml_mlp_homogeneous(dataset, covariates, treatment, outcomes):\n",
    "    theta_hat_dr_values = []\n",
    "    mse_values = []\n",
    "\n",
    "    for outcome in outcomes:\n",
    "        print(f\"Processing outcome: {outcome}\")\n",
    "        \n",
    "        X = dataset[covariates].values\n",
    "        D = dataset[treatment].values\n",
    "        Y = dataset[outcome].values\n",
    "\n",
    "        # Perform Double ML for the single outcome\n",
    "        theta_hat, mse = double_ml_single_outcome_homogeneous(X, D, Y)\n",
    "        \n",
    "        theta_hat_dr_values.append(theta_hat)\n",
    "        mse_values.append(mse)\n",
    "\n",
    "    # Create results DataFrame\n",
    "    results_df = pd.DataFrame({\n",
    "        \"Outcome\": outcomes,\n",
    "        \"Estimate\": theta_hat_dr_values,\n",
    "        \"MSE\": mse_values\n",
    "    })\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing outcome: pcorrupt\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Processing outcome: ncorrupt_os\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Processing outcome: log_valor_corrupt\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pcorrupt</td>\n",
       "      <td>-0.046082</td>\n",
       "      <td>0.038488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ncorrupt_os</td>\n",
       "      <td>0.003424</td>\n",
       "      <td>0.019541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_valor_corrupt</td>\n",
       "      <td>-0.952303</td>\n",
       "      <td>30.573879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Outcome  Estimate        MSE\n",
       "0           pcorrupt -0.046082   0.038488\n",
       "1        ncorrupt_os  0.003424   0.019541\n",
       "2  log_valor_corrupt -0.952303  30.573879"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example Usage\n",
    "mlp_result_df_homo = run_double_ml_mlp_homogeneous(\n",
    "    dataset=double_ml_dataset, \n",
    "    covariates=all_covariates, \n",
    "    treatment=treatment, \n",
    "    outcomes=outcomes\n",
    ")\n",
    "mlp_result_df_homo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assuming Heteogeneous treatment effct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train propensity score model using Gradient Boosting\n",
    "def train_gb_pscore(X_train, D_train, X_test, n_estimators=100, max_depth=3, random_state=42):\n",
    "    gb_pscore = GradientBoostingClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=random_state)\n",
    "    gb_pscore.fit(X_train, D_train)\n",
    "    propensity_scores = gb_pscore.predict_proba(X_test)[:, 1]\n",
    "    return propensity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train outcome model for treated/untreated groups\n",
    "def train_gb_outcome(X_train, Y_train, X_test, n_estimators=100, max_depth=3, random_state=42):\n",
    "    gb_model = GradientBoostingRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=random_state)\n",
    "    gb_model.fit(X_train, Y_train)\n",
    "    predictions = gb_model.predict(X_test)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the doubly robust treatment effect\n",
    "def calculate_dr_treatment_effect(X, D, Y, k_folds=5):\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # K-Fold Cross-Fitting\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    dr_ate_fold = []\n",
    "    mse_fold = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X_scaled):\n",
    "        X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "        D_train, D_test = D.iloc[train_index], D.iloc[test_index]\n",
    "        Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "        \n",
    "        # Step 1: Estimate propensity scores\n",
    "        propensity_scores = train_gb_pscore(X_train, D_train, X_test)\n",
    "        \n",
    "        # Step 2: Trim p-scores (0.01, 0.99)\n",
    "        trimmed_indices = (propensity_scores > 0.01) & (propensity_scores < 0.99)\n",
    "        trimmed_X = X_test[trimmed_indices]\n",
    "        trimmed_D = D_test.iloc[trimmed_indices]\n",
    "        trimmed_Y = Y_test.iloc[trimmed_indices]\n",
    "        trimmed_pscore = propensity_scores[trimmed_indices]\n",
    "        \n",
    "        # Step 3: Fit outcome models for treated and untreated groups\n",
    "        gamma1 = train_gb_outcome(X_train[D_train == 1], Y_train[D_train == 1], trimmed_X)\n",
    "        gamma0 = train_gb_outcome(X_train[D_train == 0], Y_train[D_train == 0], trimmed_X)\n",
    "        \n",
    "        # Step 4: Calculate doubly robust estimates\n",
    "        trimmed_data = pd.DataFrame({\n",
    "            \"gamma1\": gamma1,\n",
    "            \"gamma0\": gamma0,\n",
    "            \"D\": trimmed_D.values,\n",
    "            \"Y\": trimmed_Y.values,\n",
    "            \"pscore\": trimmed_pscore\n",
    "        })\n",
    "        \n",
    "        trimmed_data['Y1_dr'] = (\n",
    "            trimmed_data['gamma1'] +\n",
    "            (trimmed_data['D'] / trimmed_data['pscore']) * (trimmed_data['Y'] - trimmed_data['gamma1'])\n",
    "        )\n",
    "        \n",
    "        trimmed_data['Y0_dr'] = (\n",
    "            trimmed_data['gamma0'] +\n",
    "            ((1 - trimmed_data['D']) / (1 - trimmed_data['pscore'])) * (trimmed_data['Y'] - trimmed_data['gamma0'])\n",
    "        )\n",
    "        \n",
    "        # Step 5: Calculate treatment effect and MSE for the fold\n",
    "        dr_ate_fold.append(np.mean(trimmed_data['Y1_dr'] - trimmed_data['Y0_dr']))\n",
    "        mse_fold.append(mean_squared_error(\n",
    "            trimmed_data['Y'],\n",
    "            trimmed_data['Y1_dr'] * trimmed_data['D'] + trimmed_data['Y0_dr'] * (1 - trimmed_data['D'])\n",
    "        ))\n",
    "    \n",
    "    # Average treatment effect and MSE across folds\n",
    "    dr_ate = np.mean(dr_ate_fold)\n",
    "    mse = np.mean(mse_fold)\n",
    "    return dr_ate, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gradient_boosting_dml(dataset, covariates, treatment, outcomes):\n",
    "    theta_hat_dr_values = []\n",
    "    mse_values = []\n",
    "\n",
    "    for outcome in outcomes:\n",
    "        print(f\"Processing outcome: {outcome}\")\n",
    "        X = dataset[covariates]\n",
    "        D = dataset[treatment]\n",
    "        Y = dataset[outcome]\n",
    "\n",
    "        dr_ate, mse = calculate_dr_treatment_effect(X, D, Y)\n",
    "        theta_hat_dr_values.append(dr_ate)\n",
    "        mse_values.append(mse)\n",
    "    \n",
    "    # Create Results DataFrame\n",
    "    results_df = pd.DataFrame({\n",
    "        \"Outcome\": outcomes,\n",
    "        \"Estimate\": theta_hat_dr_values,\n",
    "        \"MSE\": mse_values\n",
    "    })\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing outcome: pcorrupt\n",
      "Processing outcome: ncorrupt_os\n",
      "Processing outcome: log_valor_corrupt\n"
     ]
    }
   ],
   "source": [
    "gb_result_df_hetero = run_gradient_boosting_dml(\n",
    "    dataset=double_ml_dataset, \n",
    "    covariates=all_covariates, \n",
    "    treatment=treatment, \n",
    "    outcomes=outcomes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doubly Robust Treatment Effect Estimates with Cross-Fitting (Gradient Boosting):\n",
      "             Outcome  Estimate         MSE\n",
      "0           pcorrupt -0.025620    0.141620\n",
      "1        ncorrupt_os -0.006851    0.023093\n",
      "2  log_valor_corrupt -0.247871  302.724438\n"
     ]
    }
   ],
   "source": [
    "print(\"Doubly Robust Treatment Effect Estimates with Cross-Fitting (Gradient Boosting):\")\n",
    "print(gb_result_df_hetero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized Mean Differences (SMD):\n",
      "[ 0.09030618 -0.05935758  0.00913778 -0.27511533  0.3215796   0.19087747\n",
      " -0.07261261 -0.11765553  0.10332962  0.06669827  0.0727699   0.07814006\n",
      "  0.08917901  0.15880263 -0.04890726 -0.12775864  0.11462099  0.14063892\n",
      "  0.1361354   0.07878148  0.07599797 -0.08790506  0.04971291  0.10499881\n",
      "  0.18966639 -0.0531381   0.07196117  0.09511551  0.25702069  0.2637618\n",
      " -0.37182915 -0.01454558 -0.06225104 -0.01587706  0.03335009  0.01973417\n",
      " -0.02683086 -0.02058486  0.0215772  -0.08640551  0.14543476  0.0617282\n",
      " -0.10543865 -0.09541292  0.20161219  0.08325514  0.07075639 -0.03389309\n",
      "  0.02665818 -0.07137314  0.04641801  0.00743784  0.00947106  0.06753383\n",
      " -0.12445269 -0.08719094 -0.03280061 -0.07907675 -0.13699253 -0.0589075\n",
      " -0.12388311  0.02808309  0.14579819  0.03994939 -0.1023675   0.12261033\n",
      "  0.037131  ]\n"
     ]
    }
   ],
   "source": [
    "def compute_propensity_scores(X, D):\n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Define Gradient Boosting Classifier\n",
    "    gb_model = GradientBoostingClassifier(n_estimators=100, max_depth=3, learning_rate=0.1, random_state=42)\n",
    "    \n",
    "    # Train the Gradient Boosting model\n",
    "    gb_model.fit(X_scaled, D)\n",
    "    \n",
    "    # Predict propensity scores\n",
    "    propensity_scores = gb_model.predict_proba(X_scaled)[:, 1]  # Probability of treatment\n",
    "    return propensity_scores\n",
    "\n",
    "smd_values = compute_smd(double_ml_dataset, all_covariates, treatment)\n",
    "\n",
    "\n",
    "# Print only the SMD\n",
    "print(\"Standardized Mean Differences (SMD):\")\n",
    "print(smd_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assuming Homogeneous treatment effct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dr_homogeneous_gb(X, D, Y, k_folds=5):\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # K-Fold Cross-Fitting\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    W_hat, V_hat = np.zeros(len(Y)), np.zeros(len(Y))\n",
    "    mse_fold = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X_scaled):\n",
    "        X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "        D_train, D_test = D[train_index], D[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "        # Step 1: Estimate propensity scores using the provided function\n",
    "        pi_hat = train_gb_pscore(X_train, D_train, X_test)  # Function from the image\n",
    "\n",
    "        # Trim propensity scores (0.01, 0.99)\n",
    "        trimmed_indices = (pi_hat > 0.01) & (pi_hat < 0.99)\n",
    "        trimmed_X, trimmed_D, trimmed_Y = X_test[trimmed_indices], D_test[trimmed_indices], Y_test[trimmed_indices]\n",
    "        trimmed_pscore = pi_hat[trimmed_indices]\n",
    "\n",
    "        # Step 2: Estimate E[Y|X] using the provided function\n",
    "        gamma_hat = train_gb_outcome(X_train, Y_train, trimmed_X)  # Function from the image\n",
    "\n",
    "        # Step 3: Calculate residuals W_hat and V_hat\n",
    "        W_hat[test_index[trimmed_indices]] = trimmed_Y - gamma_hat\n",
    "        V_hat[test_index[trimmed_indices]] = trimmed_D - trimmed_pscore\n",
    "\n",
    "        # Step 4: Calculate MSE for this fold\n",
    "        mse_fold.append(mean_squared_error(trimmed_Y, gamma_hat))\n",
    "    \n",
    "    # Step 5: Regress W_hat on V_hat to estimate theta_0\n",
    "    regression = LinearRegression()\n",
    "    regression.fit(V_hat.reshape(-1, 1), W_hat)\n",
    "    theta_hat = regression.coef_[0]\n",
    "\n",
    "    return theta_hat, np.mean(mse_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dr_homogeneous_gb(dataset, covariates, treatment, outcomes):\n",
    "    theta_hat_dr_values = []\n",
    "    mse_values = []\n",
    "\n",
    "    for outcome in outcomes:\n",
    "        print(f\"Processing outcome: {outcome}\")\n",
    "        X = dataset[covariates].values\n",
    "        D = dataset[treatment].values\n",
    "        Y = dataset[outcome].values\n",
    "\n",
    "        # Call the homogeneous treatment effect function\n",
    "        dr_ate, mse = calculate_dr_homogeneous_gb(X, D, Y)\n",
    "        theta_hat_dr_values.append(dr_ate)\n",
    "        mse_values.append(mse)\n",
    "\n",
    "    # Create Results DataFrame\n",
    "    results_df = pd.DataFrame({\n",
    "        \"Outcome\": outcomes,\n",
    "        \"Estimate\": theta_hat_dr_values,\n",
    "        \"MSE\": mse_values\n",
    "    })\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing outcome: pcorrupt\n",
      "Processing outcome: ncorrupt_os\n",
      "Processing outcome: log_valor_corrupt\n"
     ]
    }
   ],
   "source": [
    "gb_result_df_homo = run_dr_homogeneous_gb(\n",
    "    dataset=double_ml_dataset, \n",
    "    covariates=all_covariates, \n",
    "    treatment=treatment, \n",
    "    outcomes=outcomes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doubly Robust Treatment Effect Estimates with Cross-Fitting (Homogeneous, Gradient Boosting):\n",
      "             Outcome  Estimate        MSE\n",
      "0           pcorrupt -0.018570   0.012256\n",
      "1        ncorrupt_os -0.006758   0.002253\n",
      "2  log_valor_corrupt -0.805899  28.775320\n"
     ]
    }
   ],
   "source": [
    "print(\"Doubly Robust Treatment Effect Estimates with Cross-Fitting (Homogeneous, Gradient Boosting):\")\n",
    "print(gb_result_df_homo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Estimates:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso: (hetero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pcorrupt</td>\n",
       "      <td>-0.020347</td>\n",
       "      <td>0.016255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ncorrupt_os</td>\n",
       "      <td>-0.008265</td>\n",
       "      <td>0.003704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_valor_corrupt</td>\n",
       "      <td>-0.997271</td>\n",
       "      <td>38.910263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Outcome  Estimate        MSE\n",
       "0           pcorrupt -0.020347   0.016255\n",
       "1        ncorrupt_os -0.008265   0.003704\n",
       "2  log_valor_corrupt -0.997271  38.910263"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only mayor_covariates:\n",
    "ls_result_df_1_he = estimate_dr_for_outcomes_lasso(double_ml_dataset, mayor_covariates, treatment, outcomes)\n",
    "ls_result_df_1_he"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pcorrupt</td>\n",
       "      <td>-0.020045</td>\n",
       "      <td>0.016547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ncorrupt_os</td>\n",
       "      <td>-0.006737</td>\n",
       "      <td>0.003703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_valor_corrupt</td>\n",
       "      <td>-0.920564</td>\n",
       "      <td>37.689457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Outcome  Estimate        MSE\n",
       "0           pcorrupt -0.020045   0.016547\n",
       "1        ncorrupt_os -0.006737   0.003703\n",
       "2  log_valor_corrupt -0.920564  37.689457"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mayor_covariates + municipal_covariates\n",
    "ma_mu=(mayor_covariates +municipal_covariates)\n",
    "ls_result_df_2_he = estimate_dr_for_outcomes_lasso(double_ml_dataset, ma_mu, treatment, outcomes)\n",
    "ls_result_df_2_he"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pcorrupt</td>\n",
       "      <td>-0.021861</td>\n",
       "      <td>0.016859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ncorrupt_os</td>\n",
       "      <td>-0.007023</td>\n",
       "      <td>0.003565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_valor_corrupt</td>\n",
       "      <td>-1.036228</td>\n",
       "      <td>36.969845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Outcome  Estimate        MSE\n",
       "0           pcorrupt -0.021861   0.016859\n",
       "1        ncorrupt_os -0.007023   0.003565\n",
       "2  log_valor_corrupt -1.036228  36.969845"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mayor_covariants + municipal_covariantes + political_judicial_covariants\n",
    "ma_mu_pl=(\n",
    "    mayor_covariates +\n",
    "    municipal_covariates +\n",
    "    political_judicial_covariates)\n",
    "ls_result_df_3_he = estimate_dr_for_outcomes_lasso(double_ml_dataset, ma_mu_pl, treatment, outcomes)\n",
    "ls_result_df_3_he\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pcorrupt</td>\n",
       "      <td>-0.022035</td>\n",
       "      <td>0.017367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ncorrupt_os</td>\n",
       "      <td>-0.008515</td>\n",
       "      <td>0.003262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_valor_corrupt</td>\n",
       "      <td>-1.067475</td>\n",
       "      <td>36.140774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Outcome  Estimate        MSE\n",
       "0           pcorrupt -0.022035   0.017367\n",
       "1        ncorrupt_os -0.008515   0.003262\n",
       "2  log_valor_corrupt -1.067475  36.140774"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All Covariants (plus two dummies)\n",
    "ls_result_df_4_he = estimate_dr_for_outcomes_lasso(double_ml_dataset, all_covariates, treatment, outcomes)\n",
    "ls_result_df_4_he"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest: (hetero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing outcome: pcorrupt\n",
      "Processing outcome: ncorrupt_os\n",
      "Processing outcome: log_valor_corrupt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pcorrupt</td>\n",
       "      <td>-0.023557</td>\n",
       "      <td>0.016103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ncorrupt_os</td>\n",
       "      <td>-0.008990</td>\n",
       "      <td>0.003696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_valor_corrupt</td>\n",
       "      <td>-0.940074</td>\n",
       "      <td>41.774628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Outcome  Estimate        MSE\n",
       "0           pcorrupt -0.023557   0.016103\n",
       "1        ncorrupt_os -0.008990   0.003696\n",
       "2  log_valor_corrupt -0.940074  41.774628"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only mayor_covariates:\n",
    "rf_result_df_1_he = run_dr_estimation_rf(double_ml_dataset, mayor_covariates, treatment, outcomes)\n",
    "rf_result_df_1_he"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing outcome: pcorrupt\n",
      "Processing outcome: ncorrupt_os\n",
      "Processing outcome: log_valor_corrupt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pcorrupt</td>\n",
       "      <td>-0.018304</td>\n",
       "      <td>0.015393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ncorrupt_os</td>\n",
       "      <td>-0.003374</td>\n",
       "      <td>0.004371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_valor_corrupt</td>\n",
       "      <td>-0.777579</td>\n",
       "      <td>35.103503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Outcome  Estimate        MSE\n",
       "0           pcorrupt -0.018304   0.015393\n",
       "1        ncorrupt_os -0.003374   0.004371\n",
       "2  log_valor_corrupt -0.777579  35.103503"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mayor_covariates + municipal_covariates\n",
    "ma_mu=(mayor_covariates +municipal_covariates)\n",
    "rf_result_df_2_he = run_dr_estimation_rf(double_ml_dataset, ma_mu, treatment, outcomes)\n",
    "rf_result_df_2_he"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing outcome: pcorrupt\n",
      "Processing outcome: ncorrupt_os\n",
      "Processing outcome: log_valor_corrupt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pcorrupt</td>\n",
       "      <td>-0.024600</td>\n",
       "      <td>0.019694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ncorrupt_os</td>\n",
       "      <td>-0.005321</td>\n",
       "      <td>0.003509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_valor_corrupt</td>\n",
       "      <td>-0.880052</td>\n",
       "      <td>39.609270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Outcome  Estimate        MSE\n",
       "0           pcorrupt -0.024600   0.019694\n",
       "1        ncorrupt_os -0.005321   0.003509\n",
       "2  log_valor_corrupt -0.880052  39.609270"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mayor_covariants + municipal_covariantes + political_judicial_covariants\n",
    "ma_mu_pl=(\n",
    "    mayor_covariates +\n",
    "    municipal_covariates +\n",
    "    political_judicial_covariates)\n",
    "rf_result_df_3_he = run_dr_estimation_rf(double_ml_dataset, ma_mu_pl, treatment, outcomes)\n",
    "rf_result_df_3_he"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing outcome: pcorrupt\n",
      "Processing outcome: ncorrupt_os\n",
      "Processing outcome: log_valor_corrupt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pcorrupt</td>\n",
       "      <td>-0.026246</td>\n",
       "      <td>0.018019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ncorrupt_os</td>\n",
       "      <td>-0.007434</td>\n",
       "      <td>0.002945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_valor_corrupt</td>\n",
       "      <td>-0.910680</td>\n",
       "      <td>33.156128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Outcome  Estimate        MSE\n",
       "0           pcorrupt -0.026246   0.018019\n",
       "1        ncorrupt_os -0.007434   0.002945\n",
       "2  log_valor_corrupt -0.910680  33.156128"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All Covariants (plus two dummies)\n",
    "rf_result_df_4_he = run_dr_estimation_rf(double_ml_dataset, all_covariates, treatment, outcomes)\n",
    "rf_result_df_4_he"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP: (hetero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing outcome: pcorrupt\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Processing outcome: ncorrupt_os\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Processing outcome: log_valor_corrupt\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pcorrupt</td>\n",
       "      <td>0.040866</td>\n",
       "      <td>1.238286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ncorrupt_os</td>\n",
       "      <td>-0.143094</td>\n",
       "      <td>9.896389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_valor_corrupt</td>\n",
       "      <td>-0.634218</td>\n",
       "      <td>117.159203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Outcome  Estimate         MSE\n",
       "0           pcorrupt  0.040866    1.238286\n",
       "1        ncorrupt_os -0.143094    9.896389\n",
       "2  log_valor_corrupt -0.634218  117.159203"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only mayor_covariates:\n",
    "mlp_result_df_1_he = run_double_ml_mlp(double_ml_dataset, mayor_covariates, outcomes)\n",
    "mlp_result_df_1_he"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing outcome: pcorrupt\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Processing outcome: ncorrupt_os\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Processing outcome: log_valor_corrupt\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pcorrupt</td>\n",
       "      <td>-0.007753</td>\n",
       "      <td>0.030768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ncorrupt_os</td>\n",
       "      <td>0.020973</td>\n",
       "      <td>0.436346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_valor_corrupt</td>\n",
       "      <td>0.348335</td>\n",
       "      <td>475.654480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Outcome  Estimate         MSE\n",
       "0           pcorrupt -0.007753    0.030768\n",
       "1        ncorrupt_os  0.020973    0.436346\n",
       "2  log_valor_corrupt  0.348335  475.654480"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mayor_covariates + municipal_covariates\n",
    "mlp_result_df_2_he = run_double_ml_mlp(double_ml_dataset, ma_mu, outcomes)\n",
    "mlp_result_df_2_he"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing outcome: pcorrupt\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Processing outcome: ncorrupt_os\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Processing outcome: log_valor_corrupt\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pcorrupt</td>\n",
       "      <td>-0.004054</td>\n",
       "      <td>0.144278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ncorrupt_os</td>\n",
       "      <td>-0.026239</td>\n",
       "      <td>0.029542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_valor_corrupt</td>\n",
       "      <td>-0.969615</td>\n",
       "      <td>45.023560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Outcome  Estimate        MSE\n",
       "0           pcorrupt -0.004054   0.144278\n",
       "1        ncorrupt_os -0.026239   0.029542\n",
       "2  log_valor_corrupt -0.969615  45.023560"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mayor_covariants + municipal_covariantes + political_judicial_covariants\n",
    "mlp_result_df_3_he = run_double_ml_mlp(double_ml_dataset, ma_mu_pl, outcomes)\n",
    "mlp_result_df_3_he"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing outcome: pcorrupt\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Processing outcome: ncorrupt_os\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Processing outcome: log_valor_corrupt\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pcorrupt</td>\n",
       "      <td>-0.044739</td>\n",
       "      <td>0.112768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ncorrupt_os</td>\n",
       "      <td>0.010020</td>\n",
       "      <td>0.090483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_valor_corrupt</td>\n",
       "      <td>-1.142586</td>\n",
       "      <td>52.399792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Outcome  Estimate        MSE\n",
       "0           pcorrupt -0.044739   0.112768\n",
       "1        ncorrupt_os  0.010020   0.090483\n",
       "2  log_valor_corrupt -1.142586  52.399792"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All Covariants (plus two dummies)\n",
    "mlp_result_df_4_he = run_double_ml_mlp(double_ml_dataset, all_covariates,outcomes)\n",
    "mlp_result_df_4_he"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradiant Boosting: (hetero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing outcome: pcorrupt\n",
      "Processing outcome: ncorrupt_os\n",
      "Processing outcome: log_valor_corrupt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pcorrupt</td>\n",
       "      <td>-0.026604</td>\n",
       "      <td>0.055311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ncorrupt_os</td>\n",
       "      <td>-0.007467</td>\n",
       "      <td>0.014383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_valor_corrupt</td>\n",
       "      <td>-0.541075</td>\n",
       "      <td>189.042152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Outcome  Estimate         MSE\n",
       "0           pcorrupt -0.026604    0.055311\n",
       "1        ncorrupt_os -0.007467    0.014383\n",
       "2  log_valor_corrupt -0.541075  189.042152"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only mayor_covariants\n",
    "gb_result_df_1_he = run_gradient_boosting_dml(double_ml_dataset, mayor_covariates, treatment, outcomes)\n",
    "gb_result_df_1_he"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing outcome: pcorrupt\n",
      "Processing outcome: ncorrupt_os\n",
      "Processing outcome: log_valor_corrupt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pcorrupt</td>\n",
       "      <td>-0.015835</td>\n",
       "      <td>0.088136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ncorrupt_os</td>\n",
       "      <td>-0.009822</td>\n",
       "      <td>0.040957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_valor_corrupt</td>\n",
       "      <td>-0.703064</td>\n",
       "      <td>280.039053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Outcome  Estimate         MSE\n",
       "0           pcorrupt -0.015835    0.088136\n",
       "1        ncorrupt_os -0.009822    0.040957\n",
       "2  log_valor_corrupt -0.703064  280.039053"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mayor_covariates + municipal_covariates\n",
    "gb_result_df_2_he = run_gradient_boosting_dml(double_ml_dataset, ma_mu, treatment, outcomes)\n",
    "gb_result_df_2_he"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing outcome: pcorrupt\n",
      "Processing outcome: ncorrupt_os\n",
      "Processing outcome: log_valor_corrupt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pcorrupt</td>\n",
       "      <td>-0.025548</td>\n",
       "      <td>0.087833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ncorrupt_os</td>\n",
       "      <td>-0.009761</td>\n",
       "      <td>0.022170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_valor_corrupt</td>\n",
       "      <td>-0.653247</td>\n",
       "      <td>208.179641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Outcome  Estimate         MSE\n",
       "0           pcorrupt -0.025548    0.087833\n",
       "1        ncorrupt_os -0.009761    0.022170\n",
       "2  log_valor_corrupt -0.653247  208.179641"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mayor_covariants + municipal_covariantes + political_judicial_covariants\n",
    "gb_result_df_3_he = run_gradient_boosting_dml(double_ml_dataset, ma_mu_pl, treatment, outcomes)\n",
    "gb_result_df_3_he"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing outcome: pcorrupt\n",
      "Processing outcome: ncorrupt_os\n",
      "Processing outcome: log_valor_corrupt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pcorrupt</td>\n",
       "      <td>-0.025620</td>\n",
       "      <td>0.141620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ncorrupt_os</td>\n",
       "      <td>-0.006851</td>\n",
       "      <td>0.023093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_valor_corrupt</td>\n",
       "      <td>-0.247871</td>\n",
       "      <td>302.724438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Outcome  Estimate         MSE\n",
       "0           pcorrupt -0.025620    0.141620\n",
       "1        ncorrupt_os -0.006851    0.023093\n",
       "2  log_valor_corrupt -0.247871  302.724438"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All Covariants (plus two dummies)\n",
    "gb_result_df_4_he = run_gradient_boosting_dml(double_ml_dataset, all_covariates,treatment, outcomes)\n",
    "gb_result_df_4_he"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_estimate_mse(result_df, outcome_name):\n",
    "    row = result_df[result_df['Outcome'] == outcome_name]\n",
    "    estimate = row['Estimate'].values[0]\n",
    "    mse = row['MSE'].values[0]\n",
    "    return f\"{estimate:.6f} ({mse:.6f})\"\n",
    "# Create a list of models and their corresponding result dataframes\n",
    "models = [\"Lasso\", \"Random Forest\", \"Multiple-layer Perceptron\", \"Gradient Boosting\"]\n",
    "result_dfs_1 = [ls_result_df_1_he, rf_result_df_1_he, mlp_result_df_1_he, gb_result_df_1_he]\n",
    "result_dfs_2 = [ls_result_df_2_he, rf_result_df_2_he, mlp_result_df_2_he, gb_result_df_2_he]\n",
    "result_dfs_3 = [ls_result_df_3_he, rf_result_df_3_he, mlp_result_df_3_he, gb_result_df_3_he]\n",
    "result_dfs_4 = [ls_result_df_4_he, rf_result_df_4_he, mlp_result_df_4_he, gb_result_df_4_he]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   ML Method          Covariates_1          Covariates_2  \\\n",
      "0                      Lasso  -0.020347 (0.016255)  -0.020045 (0.016547)   \n",
      "1              Random Forest  -0.023557 (0.016103)  -0.018304 (0.015393)   \n",
      "2  Multiple-layer Perceptron   0.040866 (1.238286)  -0.007753 (0.030768)   \n",
      "3          Gradient Boosting  -0.026604 (0.055311)  -0.015835 (0.088136)   \n",
      "\n",
      "           Covariates_3          Covariates_4  \n",
      "0  -0.021861 (0.016859)  -0.022035 (0.017367)  \n",
      "1  -0.024600 (0.019694)  -0.026246 (0.018019)  \n",
      "2  -0.004054 (0.144278)  -0.044739 (0.112768)  \n",
      "3  -0.025548 (0.087833)  -0.025620 (0.141620)  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "outcome_name = \"pcorrupt\"\n",
    "\n",
    "# Combine results into a single DataFrame\n",
    "combined_results_pc = pd.DataFrame({\n",
    "    \"ML Method\": models,\n",
    "    \"Covariates_1\": [extract_estimate_mse(df, outcome_name) for df in result_dfs_1],\n",
    "    \"Covariates_2\": [extract_estimate_mse(df, outcome_name) for df in result_dfs_2],\n",
    "    \"Covariates_3\": [extract_estimate_mse(df, outcome_name) for df in result_dfs_3],\n",
    "    \"Covariates_4\": [extract_estimate_mse(df, outcome_name) for df in result_dfs_4]\n",
    "})\n",
    "\n",
    "# Display the combined results\n",
    "print(combined_results_pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   ML Method          Covariates_1          Covariates_2  \\\n",
      "0                      Lasso  -0.008265 (0.003704)  -0.006737 (0.003703)   \n",
      "1              Random Forest  -0.008990 (0.003696)  -0.003374 (0.004371)   \n",
      "2  Multiple-layer Perceptron  -0.143094 (9.896389)   0.020973 (0.436346)   \n",
      "3          Gradient Boosting  -0.007467 (0.014383)  -0.009822 (0.040957)   \n",
      "\n",
      "           Covariates_3          Covariates_4  \n",
      "0  -0.007023 (0.003565)  -0.008515 (0.003262)  \n",
      "1  -0.005321 (0.003509)  -0.007434 (0.002945)  \n",
      "2  -0.026239 (0.029542)   0.010020 (0.090483)  \n",
      "3  -0.009761 (0.022170)  -0.006851 (0.023093)  \n"
     ]
    }
   ],
   "source": [
    "outcome_name = \"ncorrupt_os\"\n",
    "\n",
    "# Combine results into a single DataFrame\n",
    "combined_results_nc = pd.DataFrame({\n",
    "    \"ML Method\": models,\n",
    "    \"Covariates_1\": [extract_estimate_mse(df, outcome_name) for df in result_dfs_1],\n",
    "    \"Covariates_2\": [extract_estimate_mse(df, outcome_name) for df in result_dfs_2],\n",
    "    \"Covariates_3\": [extract_estimate_mse(df, outcome_name) for df in result_dfs_3],\n",
    "    \"Covariates_4\": [extract_estimate_mse(df, outcome_name) for df in result_dfs_4]\n",
    "})\n",
    "\n",
    "# Display the combined results\n",
    "print(combined_results_nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   ML Method            Covariates_1            Covariates_2  \\\n",
      "0                      Lasso   -0.997271 (38.910263)   -0.920564 (37.689457)   \n",
      "1              Random Forest   -0.940074 (41.774628)   -0.777579 (35.103503)   \n",
      "2  Multiple-layer Perceptron  -0.634218 (117.159203)   0.348335 (475.654480)   \n",
      "3          Gradient Boosting  -0.541075 (189.042152)  -0.703064 (280.039053)   \n",
      "\n",
      "             Covariates_3            Covariates_4  \n",
      "0   -1.036228 (36.969845)   -1.067475 (36.140774)  \n",
      "1   -0.880052 (39.609270)   -0.910680 (33.156128)  \n",
      "2   -0.969615 (45.023560)   -1.142586 (52.399792)  \n",
      "3  -0.653247 (208.179641)  -0.247871 (302.724438)  \n"
     ]
    }
   ],
   "source": [
    "outcome_name = \"log_valor_corrupt\"\n",
    "\n",
    "# Combine results into a single DataFrame\n",
    "combined_results_lv = pd.DataFrame({\n",
    "    \"ML Method\": models,\n",
    "    \"Covariates_1\": [extract_estimate_mse(df, outcome_name) for df in result_dfs_1],\n",
    "    \"Covariates_2\": [extract_estimate_mse(df, outcome_name) for df in result_dfs_2],\n",
    "    \"Covariates_3\": [extract_estimate_mse(df, outcome_name) for df in result_dfs_3],\n",
    "    \"Covariates_4\": [extract_estimate_mse(df, outcome_name) for df in result_dfs_4]\n",
    "})\n",
    "\n",
    "# Display the combined results\n",
    "print(combined_results_lv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "info2950",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
