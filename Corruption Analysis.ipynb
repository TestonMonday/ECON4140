{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Econometric Game__: Effect of electoral accountability on corruption?\n",
    "   \n",
    "### Team 3: Katheryn Ding, Amber Wei, Max Ye\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['uf', 'nsorteio', 'totrecursos', 'tot_os', 'pop', 'purb',\n",
       "       'p_secundario', 'cod_ibge6', 'pib_capita_02', 'op_01_04',\n",
       "       ...\n",
       "       'uf_d18', 'uf_d19', 'uf_d20', 'uf_d21', 'uf_d22', 'uf_d23', 'uf_d24',\n",
       "       'uf_d25', 'uf_d26', 'esample2'],\n",
       "      dtype='object', length=116)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corruption_df = pd.read_stata(\"corruptiondata.dta\")\n",
    "corruption_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mayor Covariates: ['pref_idade_tse', 'pref_masc', 'pref_escola', 'winmargin2000', 'exp_prefeito', 'party_d1', 'party_d3', 'party_d4', 'party_d5', 'party_d6', 'party_d7', 'party_d8', 'party_d9', 'party_d10', 'party_d11', 'party_d12', 'party_d13', 'party_d14', 'party_d15', 'party_d16', 'party_d17', 'party_d18']\n",
      "Municipal Covariates: ['lpop', 'purb', 'p_secundario', 'mun_novo', 'lpib02', 'gini_ipea']\n",
      "Political and Judicial Covariates: ['ENEP2000', 'ENLP2000', 'p_cad_pref']\n",
      "Dummy Covariates: ['sorteio1', 'sorteio2', 'sorteio3', 'sorteio4', 'sorteio5', 'sorteio6', 'sorteio7', 'sorteio8', 'sorteio9', 'sorteio10', 'uf_d1', 'uf_d2', 'uf_d3', 'uf_d4', 'uf_d5', 'uf_d6', 'uf_d7', 'uf_d8', 'uf_d9', 'uf_d10', 'uf_d11', 'uf_d12', 'uf_d13', 'uf_d14', 'uf_d15', 'uf_d16', 'uf_d17', 'uf_d18', 'uf_d19', 'uf_d20', 'uf_d21', 'uf_d22', 'uf_d23', 'uf_d24', 'uf_d25', 'uf_d26']\n"
     ]
    }
   ],
   "source": [
    "# Define covariates for each category\n",
    "\n",
    "# Mayor characteristics\n",
    "mayor_covariates = [\n",
    "    \"pref_idade_tse\",  # Age\n",
    "    \"pref_masc\",       # Gender\n",
    "    \"pref_escola\",     # Schooling\n",
    "    \"winmargin2000\",   # Margin of victory in 2000\n",
    "    \"exp_prefeito\"     # Was previously a mayor in a consecutive term\n",
    "] + [col for col in corruption_df.columns if col.startswith(\"party_d\")]\n",
    "\n",
    "# Municipal characteristics\n",
    "municipal_covariates = [\n",
    "    \"lpop\",           # Log of population in 2000\n",
    "    \"purb\",           # Percentage of population in urban sectors\n",
    "    \"p_secundario\",   # Percentage with at least secondary education\n",
    "    \"mun_novo\",       # New municipality indicator\n",
    "    \"lpib02\",         # Log of GDP per capita in 2002\n",
    "    \"gini_ipea\"       # Gini coefficient\n",
    "]\n",
    "\n",
    "# Political and Judicial characteristics\n",
    "political_judicial_covariates = [\n",
    "    \"ENEP2000\",  # Effective number of parties in 2000 mayor elections\n",
    "    \"ENLP2000\",  # Effective number of parties in 2000 legislative elections\n",
    "    \"p_cad_pref\" # Proportion of legislators from the same party as the mayor\n",
    "]\n",
    "\n",
    "# Dummies\n",
    "dummy_covariates = [\n",
    "    col for col in corruption_df.columns if col.startswith(\"uf_d\") or col.startswith(\"sorteio\")\n",
    "]\n",
    "\n",
    "\n",
    "print(\"Mayor Covariates:\", mayor_covariates)\n",
    "print(\"Municipal Covariates:\", municipal_covariates)\n",
    "print(\"Political and Judicial Covariates:\", political_judicial_covariates)\n",
    "print(\"Dummy Covariates:\", dummy_covariates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Columns: Index(['first', 'pcorrupt', 'ncorrupt_os', 'valor_corrupt',\n",
      "       'log_valor_corrupt', 'pref_idade_tse', 'pref_masc', 'pref_escola',\n",
      "       'winmargin2000', 'exp_prefeito', 'party_d1', 'party_d3', 'party_d4',\n",
      "       'party_d5', 'party_d6', 'party_d7', 'party_d8', 'party_d9', 'party_d10',\n",
      "       'party_d11', 'party_d12', 'party_d13', 'party_d14', 'party_d15',\n",
      "       'party_d16', 'party_d17', 'party_d18', 'lpop', 'purb', 'p_secundario',\n",
      "       'mun_novo', 'lpib02', 'gini_ipea', 'ENEP2000', 'ENLP2000', 'p_cad_pref',\n",
      "       'sorteio1', 'sorteio2', 'sorteio3', 'sorteio4', 'sorteio5', 'sorteio6',\n",
      "       'sorteio7', 'sorteio8', 'sorteio9', 'sorteio10', 'uf_d1', 'uf_d2',\n",
      "       'uf_d3', 'uf_d4', 'uf_d5', 'uf_d6', 'uf_d7', 'uf_d8', 'uf_d9', 'uf_d10',\n",
      "       'uf_d11', 'uf_d12', 'uf_d13', 'uf_d14', 'uf_d15', 'uf_d16', 'uf_d17',\n",
      "       'uf_d18', 'uf_d19', 'uf_d20', 'uf_d21', 'uf_d22', 'uf_d23', 'uf_d24',\n",
      "       'uf_d25', 'uf_d26'],\n",
      "      dtype='object')\n",
      "Number of rows in the Dataset: 467\n"
     ]
    }
   ],
   "source": [
    "corruption_df[\"log_valor_corrupt\"] = np.log(corruption_df[\"valor_corrupt\"] + 1)\n",
    "\n",
    "# Define the treatment and outcome variables\n",
    "treatment = \"first\"  \n",
    "outcomes = [\"pcorrupt\", \"ncorrupt_os\", \"valor_corrupt\",'log_valor_corrupt'] \n",
    "\n",
    "# Use all covariates\n",
    "all_covariates = (\n",
    "    mayor_covariates +\n",
    "    municipal_covariates +\n",
    "    political_judicial_covariates +\n",
    "    dummy_covariates\n",
    ")\n",
    "#set up dataset:\n",
    "required_columns = [treatment] + outcomes + all_covariates\n",
    "double_ml_dataset = corruption_df[required_columns].dropna()\n",
    "\n",
    "print(\"Dataset Columns:\", double_ml_dataset.columns)\n",
    "print(\"Number of rows in the Dataset:\", double_ml_dataset.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doubly Robust Treatment Effect Estimates with Cross-Fitting:\n",
      "[np.float32(-0.0220353), np.float32(-0.0085152965), np.float32(-148571.44), np.float32(-1.0674746)]\n"
     ]
    }
   ],
   "source": [
    "theta_hat_dr_values = []\n",
    "\n",
    "# Loop through each outcome\n",
    "for outcome in outcomes:\n",
    "    \n",
    "    X = double_ml_dataset[all_covariates]\n",
    "    D = double_ml_dataset[treatment]\n",
    "    Y = double_ml_dataset[outcome]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Prepare 5-Fold Cross-Fitting\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    dr_ate_fold = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_scaled):\n",
    "        X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "        D_train, D_test = D.iloc[train_index], D.iloc[test_index]\n",
    "        Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "        \n",
    "        # Estimate propensity scores using Lasso\n",
    "        lasso_pscore = LassoCV(alphas=np.logspace(-4, 0, 50), cv=5, random_state=42).fit(X_train, D_train)\n",
    "        D_pred = lasso_pscore.predict(X_test)\n",
    "        propensity_scores = expit(D_pred) \n",
    "        \n",
    "        # Trim p-scores (0.01, 0.99)\n",
    "        trimmed_indices = (propensity_scores > 0.01) & (propensity_scores < 0.99)\n",
    "        trimmed_X = X_test[trimmed_indices]\n",
    "        trimmed_D = D_test.iloc[trimmed_indices]\n",
    "        trimmed_Y = Y_test.iloc[trimmed_indices]\n",
    "        trimmed_pscore = propensity_scores[trimmed_indices]\n",
    "        \n",
    "        # Fit outcome models for treated (D=1) and untreated (D=0) groups\n",
    "        # Treated model\n",
    "        treated_model = LassoCV(alphas=np.logspace(-4, 0, 50), cv=5, random_state=42)\n",
    "        treated_model.fit(X_train[D_train == 1], Y_train[D_train == 1])\n",
    "        gamma1 = treated_model.predict(trimmed_X)\n",
    "        \n",
    "        # Untreated model\n",
    "        untreated_model = LassoCV(alphas=np.logspace(-4, 0, 50), cv=5, random_state=42)\n",
    "        untreated_model.fit(X_train[D_train == 0], Y_train[D_train == 0])\n",
    "        gamma0 = untreated_model.predict(trimmed_X)\n",
    "        \n",
    "        # Step 3: Calculate doubly robust estimates for potential outcomes\n",
    "        trimmed_data = pd.DataFrame({\n",
    "            \"gamma1\": gamma1,\n",
    "            \"gamma0\": gamma0,\n",
    "            \"D\": trimmed_D.values,\n",
    "            \"Y\": trimmed_Y.values,\n",
    "            \"pscore\": trimmed_pscore,\n",
    "        })\n",
    "        \n",
    "        # DR Estimate for Y(1)\n",
    "        trimmed_data['Y1_dr'] = (\n",
    "            trimmed_data['gamma1'] +\n",
    "            (trimmed_data['D'] / trimmed_data['pscore']) * (trimmed_data['Y'] - trimmed_data['gamma1'])\n",
    "        )\n",
    "        \n",
    "        # DR Estimate for Y(0)\n",
    "        trimmed_data['Y0_dr'] = (\n",
    "            trimmed_data['gamma0'] +\n",
    "            ((1 - trimmed_data['D']) / (1 - trimmed_data['pscore'])) * (trimmed_data['Y'] - trimmed_data['gamma0'])\n",
    "        )\n",
    "        \n",
    "        # Calculate treatment effect for the fold\n",
    "        dr_ate_fold.append(np.mean(trimmed_data['Y1_dr'] - trimmed_data['Y0_dr']))\n",
    "    \n",
    "    # Average treatment effect across folds\n",
    "    dr_ate = np.mean(dr_ate_fold)\n",
    "    theta_hat_dr_values.append(dr_ate)\n",
    "\n",
    "# Print the final treatment effect estimates\n",
    "print(\"Doubly Robust Treatment Effect Estimates with Cross-Fitting:\")\n",
    "print(theta_hat_dr_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assuming Homogeneous treatment effct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doubly Robust Treatment Effect Estimates with Cross-Fitting (Homogeneous):\n",
      "[np.float32(-0.022970194), np.float32(-0.008827694), np.float32(-133287.84), np.float32(-1.0866188)]\n"
     ]
    }
   ],
   "source": [
    "theta_hat_dr_values = []\n",
    "\n",
    "# Loop through each outcome\n",
    "for outcome in outcomes:\n",
    "    \n",
    "    X = double_ml_dataset[all_covariates]\n",
    "    D = double_ml_dataset[treatment]\n",
    "    Y = double_ml_dataset[outcome]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Prepare 5-Fold Cross-Fitting\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    dr_ate_fold = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_scaled):\n",
    "        X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "        D_train, D_test = D.iloc[train_index], D.iloc[test_index]\n",
    "        Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "        \n",
    "        # Estimate propensity scores using Lasso\n",
    "        lasso_pscore = LassoCV(alphas=np.logspace(-4, 0, 50), cv=5, random_state=42).fit(X_train, D_train)\n",
    "        D_pred = lasso_pscore.predict(X_test)\n",
    "        propensity_scores = expit(D_pred)  # Convert to probabilities\n",
    "        \n",
    "        # Trim p-scores (0.01, 0.99)\n",
    "        trimmed_indices = (propensity_scores > 0.01) & (propensity_scores < 0.99)\n",
    "        trimmed_X = X_test[trimmed_indices]\n",
    "        trimmed_D = D_test.iloc[trimmed_indices]\n",
    "        trimmed_Y = Y_test.iloc[trimmed_indices]\n",
    "        trimmed_pscore = propensity_scores[trimmed_indices]\n",
    "        \n",
    "        # Fit a single outcome model for homogeneous treatment effect\n",
    "        outcome_model = LassoCV(alphas=np.logspace(-4, 0, 50), cv=5, random_state=42)\n",
    "        outcome_model.fit(X_train, Y_train)\n",
    "        gamma = outcome_model.predict(trimmed_X)\n",
    "        \n",
    "        # Step 3: Calculate doubly robust estimates for potential outcomes\n",
    "        trimmed_data = pd.DataFrame({\n",
    "            \"gamma\": gamma,\n",
    "            \"D\": trimmed_D.values,\n",
    "            \"Y\": trimmed_Y.values,\n",
    "            \"pscore\": trimmed_pscore,\n",
    "        })\n",
    "        \n",
    "        # DR Estimate for Y(1)\n",
    "        trimmed_data['Y1_dr'] = (\n",
    "            trimmed_data['gamma'] +\n",
    "            (trimmed_data['D'] / trimmed_data['pscore']) * (trimmed_data['Y'] - trimmed_data['gamma'])\n",
    "        )\n",
    "        \n",
    "        # DR Estimate for Y(0)\n",
    "        trimmed_data['Y0_dr'] = (\n",
    "            trimmed_data['gamma'] +\n",
    "            ((1 - trimmed_data['D']) / (1 - trimmed_data['pscore'])) * (trimmed_data['Y'] - trimmed_data['gamma'])\n",
    "        )\n",
    "        \n",
    "        # Calculate treatment effect for the fold\n",
    "        dr_ate_fold.append(np.mean(trimmed_data['Y1_dr'] - trimmed_data['Y0_dr']))\n",
    "    \n",
    "    # Average treatment effect across folds\n",
    "    dr_ate = np.mean(dr_ate_fold)\n",
    "    theta_hat_dr_values.append(dr_ate)\n",
    "\n",
    "# Print the final treatment effect estimates\n",
    "print(\"Doubly Robust Treatment Effect Estimates with Cross-Fitting (Homogeneous):\")\n",
    "print(theta_hat_dr_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assuming Heterogeneous Treatment Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doubly Robust Treatment Effect Estimates with Cross-Fitting:\n",
      "[np.float64(-0.02624645123282341), np.float64(-0.007433930715706694), np.float64(-144203.11000315569), np.float64(-0.9106803645466292)]\n"
     ]
    }
   ],
   "source": [
    "# Assuming Heterogeneity\n",
    "\n",
    "theta_hat_dr_values = []\n",
    "\n",
    "# Loop through each outcome\n",
    "for outcome in outcomes:\n",
    "    \n",
    "    X = double_ml_dataset[all_covariates]\n",
    "    D = double_ml_dataset[treatment]\n",
    "    Y = double_ml_dataset[outcome]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Prepare 5-Fold Cross-Fitting\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    dr_ate_fold = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_scaled):\n",
    "        X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "        D_train, D_test = D.iloc[train_index], D.iloc[test_index]\n",
    "        Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "        \n",
    "        # Estimate propensity scores using Random Forest\n",
    "        rf_pscore = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "        rf_pscore.fit(X_train, D_train)\n",
    "        propensity_scores = rf_pscore.predict_proba(X_test)[:, 1]  # Probability of treatment\n",
    "        \n",
    "        # Trim p-scores (0.01, 0.99)\n",
    "        trimmed_indices = (propensity_scores > 0.01) & (propensity_scores < 0.99)\n",
    "        trimmed_X = X_test[trimmed_indices]\n",
    "        trimmed_D = D_test.iloc[trimmed_indices]\n",
    "        trimmed_Y = Y_test.iloc[trimmed_indices]\n",
    "        trimmed_pscore = propensity_scores[trimmed_indices]\n",
    "        \n",
    "        # Fit outcome models for treated (D=1) and untreated (D=0) groups using Random Forest\n",
    "        # Treated model\n",
    "        treated_model = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
    "        treated_model.fit(X_train[D_train == 1], Y_train[D_train == 1])\n",
    "        gamma1 = treated_model.predict(trimmed_X)\n",
    "        \n",
    "        # Untreated model\n",
    "        untreated_model = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
    "        untreated_model.fit(X_train[D_train == 0], Y_train[D_train == 0])\n",
    "        gamma0 = untreated_model.predict(trimmed_X)\n",
    "        \n",
    "        trimmed_data = pd.DataFrame({\n",
    "            \"gamma1\": gamma1,\n",
    "            \"gamma0\": gamma0,\n",
    "            \"D\": trimmed_D.values,\n",
    "            \"Y\": trimmed_Y.values,\n",
    "            \"pscore\": trimmed_pscore,\n",
    "        })\n",
    "        \n",
    "        # DR Estimate for Y(1)\n",
    "        trimmed_data['Y1_dr'] = (\n",
    "            trimmed_data['gamma1'] +\n",
    "            (trimmed_data['D'] / trimmed_data['pscore']) * (trimmed_data['Y'] - trimmed_data['gamma1'])\n",
    "        )\n",
    "        \n",
    "        # DR Estimate for Y(0)\n",
    "        trimmed_data['Y0_dr'] = (\n",
    "            trimmed_data['gamma0'] +\n",
    "            ((1 - trimmed_data['D']) / (1 - trimmed_data['pscore'])) * (trimmed_data['Y'] - trimmed_data['gamma0'])\n",
    "        )\n",
    "        \n",
    "        dr_ate_fold.append(np.mean(trimmed_data['Y1_dr'] - trimmed_data['Y0_dr']))\n",
    "    \n",
    "    # Average treatment effect across folds\n",
    "    dr_ate = np.mean(dr_ate_fold)\n",
    "    theta_hat_dr_values.append(dr_ate)\n",
    "\n",
    "# Print the final treatment effect estimates\n",
    "print(\"Doubly Robust Treatment Effect Estimates with Cross-Fitting:\")\n",
    "print(theta_hat_dr_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assuming Homogeneous Treatment Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing outcome: pcorrupt\n",
      "Processing outcome: ncorrupt_os\n",
      "Processing outcome: valor_corrupt\n",
      "Processing outcome: log_valor_corrupt\n",
      "Doubly Robust Treatment Effect Estimates with Cross-Fitting (Homogeneous):\n",
      "[np.float64(-0.02463704325446932), np.float64(-0.007449776512350478), np.float64(-130235.47453452607), np.float64(-0.8915841042301809)]\n"
     ]
    }
   ],
   "source": [
    "# Assuming Homogeneous effect \n",
    "theta_hat_dr_values = []\n",
    "\n",
    "# Loop through each outcome\n",
    "for outcome in outcomes:\n",
    "    \n",
    "    X = double_ml_dataset[all_covariates]\n",
    "    D = double_ml_dataset[treatment]\n",
    "    Y = double_ml_dataset[outcome]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    dr_ate_fold = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_scaled):\n",
    "        X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "        D_train, D_test = D.iloc[train_index], D.iloc[test_index]\n",
    "        Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "        \n",
    "        # Estimate propensity scores using Random Forest\n",
    "        rf_pscore = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "        rf_pscore.fit(X_train, D_train)\n",
    "        propensity_scores = rf_pscore.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Trim p-scores (0.01, 0.99)\n",
    "        trimmed_indices = (propensity_scores > 0.01) & (propensity_scores < 0.99)\n",
    "        trimmed_X = X_test[trimmed_indices]\n",
    "        trimmed_D = D_test.iloc[trimmed_indices]\n",
    "        trimmed_Y = Y_test.iloc[trimmed_indices]\n",
    "        trimmed_pscore = propensity_scores[trimmed_indices]\n",
    "        \n",
    "\n",
    "        outcome_model = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
    "        outcome_model.fit(X_train, Y_train)\n",
    "        gamma = outcome_model.predict(trimmed_X)\n",
    "        \n",
    "        # Calculate doubly robust estimates for potential outcomes\n",
    "        trimmed_data = pd.DataFrame({\n",
    "            \"gamma\": gamma,\n",
    "            \"D\": trimmed_D.values,\n",
    "            \"Y\": trimmed_Y.values,\n",
    "            \"pscore\": trimmed_pscore,\n",
    "        })\n",
    "        \n",
    "        # DR Estimate for Y(1)\n",
    "        trimmed_data['Y1_dr'] = (\n",
    "            trimmed_data['gamma'] +\n",
    "            (trimmed_data['D'] / trimmed_data['pscore']) * (trimmed_data['Y'] - trimmed_data['gamma'])\n",
    "        )\n",
    "        \n",
    "        # DR Estimate for Y(0)\n",
    "        trimmed_data['Y0_dr'] = (\n",
    "            trimmed_data['gamma'] +\n",
    "            ((1 - trimmed_data['D']) / (1 - trimmed_data['pscore'])) * (trimmed_data['Y'] - trimmed_data['gamma'])\n",
    "        )\n",
    "        \n",
    "        dr_ate_fold.append(np.mean(trimmed_data['Y1_dr'] - trimmed_data['Y0_dr']))\n",
    "    \n",
    "    # Average treatment effect across folds\n",
    "    dr_ate = np.mean(dr_ate_fold)\n",
    "    theta_hat_dr_values.append(dr_ate)\n",
    "\n",
    "# Print the final treatment effect estimates\n",
    "print(\"Doubly Robust Treatment Effect Estimates with Cross-Fitting (Homogeneous):\")\n",
    "print(theta_hat_dr_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Outcome      Estimate           MSE\n",
      "0           pcorrupt     -0.003627  1.225573e-02\n",
      "1        ncorrupt_os     -0.000977  2.253265e-03\n",
      "2      valor_corrupt  13570.270137  3.690273e+11\n",
      "3  log_valor_corrupt     -0.185162  2.877532e+01\n"
     ]
    }
   ],
   "source": [
    "gb_results = []\n",
    "\n",
    "# Loop through each outcome in the list of outcomes\n",
    "for outcome in outcomes:\n",
    "    \n",
    "    X = double_ml_dataset[all_covariates]\n",
    "    D = double_ml_dataset[treatment]\n",
    "    Y = double_ml_dataset[outcome]\n",
    "    \n",
    "    # Standardize the covariates\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Prepare 5-Fold Cross-Fitting\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    folds = []\n",
    "    for train_index, test_index in kf.split(X_scaled):\n",
    "        X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "        D_train, D_test = D.iloc[train_index], D.iloc[test_index]\n",
    "        Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "        folds.append((X_train, X_test, D_train, D_test, Y_train, Y_test))\n",
    "    \n",
    "    fold_estimates = []\n",
    "    fold_mse = []\n",
    "    \n",
    "    # Loop through folds for cross-fitting\n",
    "    for fold_idx, (X_train, X_test, D_train, D_test, Y_train, Y_test) in enumerate(folds):\n",
    "        # Train Gradient Boosting model\n",
    "        gb_model = GradientBoostingRegressor(random_state=42, n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "        gb_model.fit(X_train, Y_train)\n",
    "        \n",
    "        # Predict on test data\n",
    "        Y_pred = gb_model.predict(X_test)\n",
    "        \n",
    "        # Theta (Treatment Effect)\n",
    "        treatment_effect = (\n",
    "            np.mean(Y_pred[D_test.values == 1]) - np.mean(Y_pred[D_test.values == 0])\n",
    "        )\n",
    "        fold_estimates.append(treatment_effect)\n",
    "        \n",
    "        # MSE\n",
    "        mse = mean_squared_error(Y_test, Y_pred)\n",
    "        fold_mse.append(mse)\n",
    "    \n",
    "    # Compute overall average estimate and MSE for the current outcome\n",
    "    average_estimate = np.mean(fold_estimates)\n",
    "    average_mse = np.mean(fold_mse)\n",
    "    \n",
    "    # Store the results\n",
    "    gb_results.append({\"Outcome\": outcome, \"Estimate\": average_estimate, \"MSE\": average_mse})\n",
    "\n",
    "gb_results_df = pd.DataFrame(gb_results)\n",
    "\n",
    "print(gb_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = outcomes[0]  \n",
    "X = double_ml_dataset[all_covariates]\n",
    "D = double_ml_dataset[treatment]\n",
    "Y = double_ml_dataset[outcome]\n",
    "\n",
    "# Standardize the covariates\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Prepare 5-Fold Cross-Fitting\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Create train-test splits\n",
    "folds = []\n",
    "for train_index, test_index in kf.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    D_train, D_test = D.iloc[train_index], D.iloc[test_index]\n",
    "    Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "    folds.append((X_train, X_test, D_train, D_test, Y_train, Y_test))\n",
    "\n",
    "# Regularization Path for Lasso\n",
    "alphas = np.logspace(-4, 0, 50)  # 50 values between 10^-4 and 10^0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "  Treatment Effect Estimate: 0.00016003802844498372\n",
      "  MSE: 0.015647467677191204\n",
      "\n",
      "Fold 2:\n",
      "  Treatment Effect Estimate: -0.0006888164775919192\n",
      "  MSE: 0.01649880032634493\n",
      "\n",
      "Fold 3:\n",
      "  Treatment Effect Estimate: -0.013099382864855375\n",
      "  MSE: 0.009203978743665922\n",
      "\n",
      "Fold 4:\n",
      "  Treatment Effect Estimate: 0.0018513191815970748\n",
      "  MSE: 0.008108130135200117\n",
      "\n",
      "Fold 5:\n",
      "  Treatment Effect Estimate: -0.006359663711762623\n",
      "  MSE: 0.011820252893298648\n",
      "\n",
      "Final Results:\n",
      " Average Treatment Effect Estimate: -0.0036273011688335716\n",
      " Average MSE: 0.012255725955140165\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize lists to store fold estimates and MSE\n",
    "fold_estimates = []\n",
    "fold_mse = []\n",
    "\n",
    "\n",
    "# Loop through folds for cross-fitting\n",
    "for fold_idx, (X_train, X_test, D_train, D_test, Y_train, Y_test) in enumerate(folds):\n",
    "    # Train Gradient Boosting model\n",
    "    gb_model = GradientBoostingRegressor(random_state=42).fit(X_train, Y_train)\n",
    "    \n",
    "    # Predict on test data\n",
    "    Y_pred = gb_model.predict(X_test)\n",
    "    \n",
    "    # Calculate the treatment effect\n",
    "    treatment_effect = (\n",
    "        np.mean(Y_pred[D_test.values == 1]) - np.mean(Y_pred[D_test.values == 0])\n",
    "    )\n",
    "    fold_estimates.append(treatment_effect)\n",
    "    \n",
    "    # MSE\n",
    "    mse = mean_squared_error(Y_test, Y_pred)\n",
    "    fold_mse.append(mse)\n",
    "    \n",
    "    print(f\"Fold {fold_idx + 1}:\")\n",
    "    print(f\"  Treatment Effect Estimate: {treatment_effect}\")\n",
    "    print(f\"  MSE: {mse}\")\n",
    "    print()\n",
    "\n",
    "# Compute overall average estimate and MSE\n",
    "average_estimate = np.mean(fold_estimates)\n",
    "average_mse = np.mean(fold_mse)\n",
    "\n",
    "print(\"Final Results:\")\n",
    "print(f\" Average Treatment Effect Estimate: {average_estimate}\")\n",
    "print(f\" Average MSE: {average_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis \n",
    "\n",
    "compare mse/theta,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "info2950",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
